import os
import re
import sys
import asyncio
import logging
import subprocess
import signal
import warnings
# Suppress Pydantic V1 warning on Python 3.14+
warnings.filterwarnings("ignore", category=UserWarning, module="langchain_core._api.deprecation")

from pathlib import Path
from dotenv import load_dotenv
import io
import edge_tts

# Telegram Imports
from telegram import Update, ReplyKeyboardMarkup, KeyboardButton, ReplyKeyboardRemove
from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters

# LangChain Imports
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.callbacks import AsyncCallbackHandler

# ==============================================================================
# CONFIGURATION & SETUP
# ==============================================================================

# 1. Logging Setup with Custom Formatter
class ColoredFormatter(logging.Formatter):
    """Custom formatter with colors and clean output"""
    
    # ANSI color codes
    COLORS = {
        'DEBUG': '\033[36m',    # Cyan
        'INFO': '\033[32m',     # Green
        'WARNING': '\033[33m',  # Yellow
        'ERROR': '\033[31m',    # Red
        'CRITICAL': '\033[35m', # Magenta
        'RESET': '\033[0m'      # Reset
    }
    
    def format(self, record):
        # Add color to level name
        levelname = record.levelname
        if levelname in self.COLORS:
            record.levelname = f"{self.COLORS[levelname]}{levelname}{self.COLORS['RESET']}"
        
        # Shorten format for cleaner output
        log_fmt = "%(levelname)s - %(name)s - %(message)s"
        formatter = logging.Formatter(log_fmt)
        return formatter.format(record)

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("SmartBot")

# Add colored formatter to console handler
console_handler = logging.StreamHandler()
console_handler.setFormatter(ColoredFormatter())
logger.handlers = [console_handler]
logger.setLevel(logging.INFO)

# Suppress verbose logs from httpx and google_genai
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("google_genai").setLevel(logging.WARNING)
logging.getLogger("google.genai").setLevel(logging.WARNING)
logging.getLogger("google_genai._api_client").setLevel(logging.ERROR)


# 2. Environment Variables
load_dotenv()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

# 3. Global Settings
SETTINGS = {
    "download": True,
    "fact_check": False,
    "min_fc_len": 200,
    "lang": "fa",
    "admin_id": int(TELEGRAM_CHAT_ID) if TELEGRAM_CHAT_ID else 0,
    "public_mode": False,  # If True, anyone can use. If False, only whitelist.
    "default_daily_limit": 10,  # Default daily AI requests for whitelisted users
    "free_trial_limit": 3,  # Free requests for non-whitelisted users
}

# Rate Limiting (per user)
RATE_LIMIT = {}  # user_id -> last_request_time
RATE_LIMIT_SECONDS = 5  # Minimum seconds between AI requests per user

# Access Control: Whitelist
# Format: user_id -> {"daily_limit": int, "requests_today": int, "last_reset": date}
ALLOWED_USERS = {
    # Admin is always allowed with unlimited access
}

# Access Control: Allowed Groups (empty = all groups if public_mode is True)
ALLOWED_GROUPS = set()  # Add group IDs here, e.g., {-1001234567890}

# Daily request tracking
from datetime import date
USER_DAILY_USAGE = {}  # user_id -> {"count": int, "date": str}

def get_user_limit(user_id: int) -> int:
    """Get user's daily request limit."""
    admin_id = SETTINGS["admin_id"]
    if user_id == admin_id:
        return 999  # Unlimited for admin
    
    # Whitelisted users get their custom limit or default
    if user_id in ALLOWED_USERS:
        return ALLOWED_USERS[user_id].get("daily_limit", SETTINGS["default_daily_limit"])
    
    # Non-whitelisted users get free trial limit
    return SETTINGS["free_trial_limit"]

def check_access(user_id: int, chat_id: int = None) -> tuple[bool, str]:
    """Check if user has access to use the bot. Returns (allowed, reason)."""
    admin_id = SETTINGS["admin_id"]
    
    # Admin always has unlimited access
    if user_id == admin_id:
        return True, "admin"
    
    # Check if public mode
    if SETTINGS["public_mode"]:
        return True, "public"
    
    # Whitelisted users
    if user_id in ALLOWED_USERS:
        # Check group restriction (if in a group)
        if chat_id and chat_id < 0:  # Negative ID = group
            if ALLOWED_GROUPS and chat_id not in ALLOWED_GROUPS:
                return False, "group_not_allowed"
        return True, "whitelisted"
    
    # Non-whitelisted users get free trial (check if they still have quota)
    has_quota, remaining = check_daily_limit(user_id)
    if has_quota:
        return True, "free_trial"
    
    return False, "trial_expired"

def check_daily_limit(user_id: int) -> tuple[bool, int]:
    """Check if user has remaining daily requests. Returns (allowed, remaining)."""
    # Get user's limit
    user_limit = get_user_limit(user_id)
    
    # Admin has unlimited
    if user_limit >= 999:
        return True, 999
    
    # Get today's usage
    today = str(date.today())
    if user_id not in USER_DAILY_USAGE or USER_DAILY_USAGE[user_id]["date"] != today:
        USER_DAILY_USAGE[user_id] = {"count": 0, "date": today}
    
    current_count = USER_DAILY_USAGE[user_id]["count"]
    remaining = user_limit - current_count
    
    return remaining > 0, remaining

def increment_daily_usage(user_id: int) -> int:
    """Increment user's daily usage count. Returns remaining requests."""
    today = str(date.today())
    if user_id not in USER_DAILY_USAGE or USER_DAILY_USAGE[user_id]["date"] != today:
        USER_DAILY_USAGE[user_id] = {"count": 0, "date": today}
    USER_DAILY_USAGE[user_id]["count"] += 1
    
    # Return remaining
    user_limit = get_user_limit(user_id)
    return user_limit - USER_DAILY_USAGE[user_id]["count"]


# ==============================================================================
# CALLBACK HANDLER FOR LIVE STATUS UPDATES
# ==============================================================================

class StatusUpdateCallback(AsyncCallbackHandler):
    """Updates Telegram Status Message when AI model starts generating"""
    def __init__(self, status_msg, get_msg_func):
        self.status_msg = status_msg
        self.get_msg = get_msg_func
        self.last_model = None

    async def on_llm_start(self, serialized, prompts, **kwargs):
        """Called when LLM starts - update status with model name"""
        model_raw = "AI Model"
        
        # Extract model name from serialized data
        if "kwargs" in serialized and "model" in serialized["kwargs"]:
            model_raw = serialized["kwargs"]["model"]
        elif "name" in serialized:
            model_raw = serialized["name"]
        elif "id" in serialized:
            # Sometimes model is in id field as a list
            parts = serialized["id"]
            if isinstance(parts, list) and len(parts) > 0:
                # Last element is usually the model name
                model_raw = parts[-1]
        
        # Use exact model name (e.g., "gemini-2.5-flash")
        self.last_model = model_raw
        
        try:
            text = f"üß† ÿ™ÿ≠ŸÑ€åŸÑ ÿßÿØÿπÿßŸáÿß ÿ®ÿß {model_raw}"
            await self.status_msg.edit_text(text, parse_mode='Markdown')
            logger.info(f"üì° Trying model: {model_raw}")
        except Exception as e:
            logger.debug(f"Status update failed: {e}")
            pass  # Ignore flood wait or edit errors

# User Preferences (In-Memory)
USER_LANG = {}

# ... (Localization Dictionary MESSAGES is unchanged, skipping for brevity) ...

async def cmd_check_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info("‚úÖ Command /check triggered")
    msg = update.message
    user_id = update.effective_user.id
    lang = USER_LANG.get(user_id, "fa")

    # Access Control Check
    allowed, reason = check_access(user_id, msg.chat_id)
    if not allowed:
        await msg.reply_text(get_msg("access_denied", user_id))
        return
    
    # Daily Limit Check
    has_quota, remaining = check_daily_limit(user_id)
    if not has_quota:
        limit = get_user_limit(user_id)
        await msg.reply_text(get_msg("limit_reached", user_id).format(remaining=0, limit=limit))
        return

    # Check if reply or arguments
    target_text = ""
    if msg.reply_to_message:
        # Check both text and caption (for media messages)
        target_text = msg.reply_to_message.text or msg.reply_to_message.caption or ""
    if not target_text and context.args:
        target_text = " ".join(context.args)
    
    if not target_text:
        await msg.reply_text("‚õî Reply to a message or provide text: `/check <text>`")
        return

    status_msg = await msg.reply_text(
        get_msg("analyzing", user_id),
        reply_to_message_id=msg.message_id
    )
    response = await analyze_text_gemini(target_text, status_msg, lang)
    
    # Increment usage and get remaining
    remaining = increment_daily_usage(user_id)
    
    await smart_reply(msg, status_msg, response, user_id)
    
    # Show remaining requests (skip for admin)
    if user_id != SETTINGS["admin_id"]:
        limit = get_user_limit(user_id)
        await msg.reply_text(f"üìä {remaining}/{limit} ÿØÿ±ÿÆŸàÿßÿ≥ÿ™ ÿ®ÿßŸÇ€å‚ÄåŸÖÿßŸÜÿØŸá ÿßŸÖÿ±Ÿàÿ≤")

async def global_message_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """MASTER HANDLER: Processes ALL text messages"""
    msg = update.message
    if not msg or not msg.text: return
    text = msg.text.strip()
    user = update.effective_user
    user_id = user.id
    
    # Ensure User Lang
    if user_id not in USER_LANG:
        USER_LANG[user_id] = "fa"
    lang = USER_LANG[user_id]

    logger.info(f"üì® Message received: '{text}' from {user.id} ({lang})")

    # --- 1. MENU COMMANDS (Check by Emoji/Start) --- 
    
    # Status
    if text.startswith("üìä"):
        dl_s = get_msg("dl_on") if SETTINGS["download"] else get_msg("dl_off")
        fc_s = get_msg("fc_on") if SETTINGS["fact_check"] else get_msg("fc_off")
        info = get_msg("status_fmt").format(dl=dl_s, fc=fc_s)
        await msg.reply_text(info, parse_mode='Markdown')
        return

    # Language Switching
    if "ŸÅÿßÿ±ÿ≥€å" in text:
        USER_LANG[user_id] = "fa"
        await msg.reply_text("‚úÖ ÿ≤ÿ®ÿßŸÜ ŸÅÿßÿ±ÿ≥€å ÿßŸÜÿ™ÿÆÿßÿ® ÿ¥ÿØ.", reply_markup=get_main_keyboard(user_id))
        return
    if "English" in text:
        USER_LANG[user_id] = "en"
        await msg.reply_text("‚úÖ English language selected.", reply_markup=get_main_keyboard(user_id))
        return
    if "Fran√ßais" in text:
        USER_LANG[user_id] = "fr"
        await msg.reply_text("‚úÖ Langue fran√ßaise s√©lectionn√©e.", reply_markup=get_main_keyboard(user_id))
        return
    if "ÌïúÍµ≠Ïñ¥" in text:
        USER_LANG[user_id] = "ko"
        await msg.reply_text("‚úÖ ÌïúÍµ≠Ïñ¥Í∞Ä ÏÑ†ÌÉùÎêòÏóàÏäµÎãàÎã§.", reply_markup=get_main_keyboard(user_id))
        return
    
    # Voice Button
    if text.startswith("üîä"):
        detail_text = LAST_ANALYSIS_CACHE.get(user_id)
        if not detail_text:
            await msg.reply_text("‚õî Ÿá€å⁄Ü ÿ™ÿ≠ŸÑ€åŸÑ ÿ∞ÿÆ€åÿ±Ÿá‚Äåÿ¥ÿØŸá‚Äåÿß€å ŸÖŸàÿ¨ŸàÿØ ŸÜ€åÿ≥ÿ™.")
            return
        status_msg = await msg.reply_text("üîä ÿØÿ± ÿ≠ÿßŸÑ ÿ≥ÿßÿÆÿ™ ŸÅÿß€åŸÑ ÿµŸàÿ™€å...")
        try:
            audio_buffer = await text_to_speech(detail_text, lang)
            await msg.reply_voice(voice=audio_buffer, caption="üîä ŸÜÿ≥ÿÆŸá ÿµŸàÿ™€å ÿ™ÿ≠ŸÑ€åŸÑ")
            await status_msg.delete()
        except Exception as e:
            logger.error(f"TTS Error: {e}")
            await status_msg.edit_text("‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿ≥ÿßÿÆÿ™ ŸÅÿß€åŸÑ ÿµŸàÿ™€å")
        return
        
    # Help
    if text.startswith("‚ÑπÔ∏è"):
        # Note: get_help_msg should be updated to accept user_id/lang if needed, but for now assuming it uses global logic or we update it later.
        # Assuming get_help_msg(user_id) exists from previous context? I didn't verify get_help_msg signature. 
        # Let's check get_help_msg call in previous code.. it was `get_help_msg(user_id)`?
        # Actually in Step 3835: `get_help_msg` usage wasn't shown.
        # Wait, I should not assume `get_help_msg` takes user_id if I haven't seen it. 
        # But `get_help_msg` was called in `cmd_start_handler`?
        # I'll stick to safest: check existing usage in file.
        # Existing global_message_handler (line 535) didn't show help handler.
        # Ah, looking at `get_main_keyboard`...
        # I'll just skip the Help `if` block since normally `/help` handles it?
        # No, the menu button "Help" sends "‚ÑπÔ∏è Help" text.
        await msg.reply_text("‚ÑπÔ∏è Use /help to see commands.") 
        return

    # Toggle DL
    if text.startswith("üì•"):
        SETTINGS["download"] = not SETTINGS["download"]
        state = get_msg("dl_on") if SETTINGS["download"] else get_msg("dl_off")
        await msg.reply_text(get_msg("action_dl").format(state=state))
        return

    # Toggle FC
    if text.startswith("üß†"):
        SETTINGS["fact_check"] = not SETTINGS["fact_check"]
        state = get_msg("fc_on") if SETTINGS["fact_check"] else get_msg("fc_off")
        await msg.reply_text(get_msg("action_fc").format(state=state))
        return

    # Stop (Button)
    if text.startswith("üõë") and user_id == SETTINGS["admin_id"]:
        logger.info("üõë Stop Button Triggered")
        await msg.reply_text(get_msg("bot_stop"))
        os.kill(os.getpid(), signal.SIGKILL)
        return

    # --- 2. INSTAGRAM LINK CHECK ---
    if "instagram.com" in text:
        if not SETTINGS["download"]:
            await msg.reply_text("‚ö†Ô∏è " + get_msg("dl_off"))
            return
            
        status_msg = await msg.reply_text(get_msg("downloading"))
        
        # Run yt-dlp logic
        loop = asyncio.get_event_loop()
        file_path = await loop.run_in_executor(None, download_instagram_video, text)
        
        if file_path:
            try:
                await status_msg.edit_text(get_msg("uploading", user_id))
                await msg.reply_video(
                    video=open(file_path, 'rb'), 
                    caption="üì• **Su6i Yar** | @su6i\\_yar\\_bot",
                    reply_to_message_id=msg.message_id,
                    parse_mode='Markdown'
                )
                os.remove(file_path) # Cleanup
                await status_msg.delete() 
            except Exception as e:
                logger.error(f"Upload failed: {e}")
                await status_msg.edit_text("‚ùå Error uploading video.")
        else:
            await status_msg.edit_text(get_msg("err_dl", user_id))
        return

    # --- 3. AI ANALYSIS (Fallback) ---
    
    if SETTINGS["fact_check"] and len(text) >= SETTINGS["min_fc_len"]:
        # Rate limit check
        if not check_rate_limit(user_id):
            await msg.reply_text("‚è≥ ŸÑÿ∑ŸÅÿßŸã ⁄ÜŸÜÿØ ÿ´ÿßŸÜ€åŸá ÿµÿ®ÿ± ⁄©ŸÜ€åÿØ...")
            return
        
        status_msg = await msg.reply_text(
            get_msg("analyzing", user_id),
            reply_to_message_id=msg.message_id
        )
        response = await analyze_text_gemini(text, status_msg, lang)
        
        await smart_reply(msg, status_msg, response, user_id)
        return

# ==============================================================================
# LOGIC: SMART CHAIN FACTORY (LANGCHAIN)
# ==============================================================================

def get_smart_chain():
    """Constructs the self-healing AI model chain (8-Layer Defense)"""
    logger.info("‚õìÔ∏è Building Smart AI Chain...")
    
    defaults = {"google_api_key": GEMINI_API_KEY, "temperature": 0.3}

    # 1. Gemini 2.5 Pro (Primary)
    # Enable Google Search Grounding for real-time fact checking
    primary = ChatGoogleGenerativeAI(
        model="gemini-2.5-pro", 
        **defaults,
        # Grounding: Use built-in Google Search Retrieval
        model_kwargs={"tools": [{"google_search_retrieval": {}}]}
    )
    
    # Define Fallbacks in Order
    fallback_models = [
        "gemini-1.5-pro",        # 2
        "gemini-2.5-flash",      # 3
        "gemini-2.0-flash",      # 4
        "gemini-2.5-flash-lite", # 5
        "gemini-1.5-flash",      # 6
        "gemini-1.5-flash-8b"    # 7
    ]
    
    # Create Google Runnables
    runnables = [ChatGoogleGenerativeAI(model=m, **defaults) for m in fallback_models]
    
    # 8. DeepSeek (Ultimate Fallback)
    if DEEPSEEK_API_KEY:
        deepseek = ChatOpenAI(
            base_url="https://api.deepseek.com", 
            model="deepseek-chat", 
            api_key=DEEPSEEK_API_KEY,
            temperature=0.3
        )
        runnables.append(deepseek)
        
    return primary.with_fallbacks(runnables)

# Global Cache for Details (Simple Dict: user_id -> detail_text)
# In production, use a TTL cache or database.
LAST_ANALYSIS_CACHE = {}

import time

def check_rate_limit(user_id):
    """Check if user can make AI request. Returns True if allowed."""
    now = time.time()
    last_request = RATE_LIMIT.get(user_id, 0)
    if now - last_request < RATE_LIMIT_SECONDS:
        return False
    RATE_LIMIT[user_id] = now
    return True

async def analyze_text_gemini(text, status_msg=None, lang_code="fa"):
    """Analyze text using Smart Chain Fallback"""
    if not SETTINGS["fact_check"]: return None

    # Map lang_code to English name for Prompt
    lang_map = {"fa": "Persian (Farsi)", "en": "English", "fr": "French"}
    target_lang = lang_map.get(lang_code, "Persian")

    try:
        logger.info(f"üß† STARTING AI ANALYSIS ({target_lang}) for text: {text[:20]}...")
        # Language-specific labels for comparison table
        if lang_code == "fa":
            overall_status_label = "**Ÿàÿ∂ÿπ€åÿ™ ⁄©ŸÑ€å:**"
            comparison_table_label = "**ÿ¨ÿØŸàŸÑ ŸÖŸÇÿß€åÿ≥Ÿá:**"
            text_claim_label = "‚ñ´Ô∏è **ÿßÿØÿπÿß€å ŸÖÿ™ŸÜ:**"
            research_label = "‚ñ´Ô∏è **ŸÖŸÇÿßŸÑÿßÿ™:**"
            conclusion_label = "‚ñ´Ô∏è **ŸÜÿ™€åÿ¨Ÿá ÿ™ÿ≠ŸÇ€åŸÇÿßÿ™:**"
            status_label = "‚ñ´Ô∏è **Ÿàÿ∂ÿπ€åÿ™:**"
            result_label = "**ŸÜÿ™€åÿ¨Ÿá:**"
            example_conclusion1 = "ÿ™ÿ≠ŸÇ€åŸÇÿßÿ™ ÿß€åŸÜ ŸÖ€åÿ≤ÿßŸÜ ÿÆÿ≥ÿ™⁄Ø€å ÿ±ÿß ÿ™ÿ£€å€åÿØ ŸÖ€å‚Äå⁄©ŸÜÿØ"
            example_conclusion2 = "ÿ™ÿ≠ŸÇ€åŸÇÿßÿ™ ⁄©ÿßŸáÿ¥ ÿ™ŸÖÿ±⁄©ÿ≤ ÿ±ÿß ŸÜÿ¥ÿßŸÜ ŸÖ€å‚ÄåÿØŸáÿØ ÿßŸÖÿß ÿØÿ±ÿµÿØ ÿØŸÇ€åŸÇ ŸÖÿ™ŸÅÿßŸàÿ™ ÿßÿ≥ÿ™"
            example_not_specified = "ÿØÿ± ÿ™ÿ≠ŸÇ€åŸÇÿßÿ™ ŸÖÿ¥ÿÆÿµ ŸÜÿ¥ÿØŸá"
        elif lang_code == "en":
            overall_status_label = "**Overall Status:**"
            comparison_table_label = "**Comparison Table:**"
            text_claim_label = "‚ñ´Ô∏è **Text Claim:**"
            research_label = "‚ñ´Ô∏è **Research Papers:**"
            conclusion_label = "‚ñ´Ô∏è **Research Findings:**"
            status_label = "‚ñ´Ô∏è **Status:**"
            result_label = "**Conclusion:**"
            example_conclusion1 = "Research confirms fatigue increases by this amount"
            example_conclusion2 = "Research shows concentration decreases but exact percentage varies"
            example_not_specified = "Not specified in research"
        else:  # French
            overall_status_label = "**Statut Global:**"
            comparison_table_label = "**Tableau de Comparaison:**"
            text_claim_label = "‚ñ´Ô∏è **Affirmation du Texte:**"
            research_label = "‚ñ´Ô∏è **Articles:**"
            conclusion_label = "‚ñ´Ô∏è **R√©sultats de Recherche:**"
            status_label = "‚ñ´Ô∏è **Statut:**"
            result_label = "**Conclusion:**"
            example_conclusion1 = "La recherche confirme cette augmentation de fatigue"
            example_conclusion2 = "La recherche montre une diminution de concentration mais le pourcentage exact varie"
            example_not_specified = "Non sp√©cifi√© dans la recherche"
        
        prompt_text = (
            f"You are a professional Fact-Check Assistant. Answer STRICTLY in **{target_lang}** language.\n\n"
            f"Analyze the following text and provide your response in {target_lang}.\n\n"
            "CRITICAL FORMATTING RULES:\n"
            "1. Your response MUST be split into TWO parts using: |||SPLIT|||\n"
            "2. Use ‚úÖ emoji ONLY for TRUE/VERIFIED claims\n"
            "3. Use ‚ùå emoji ONLY for FALSE/INCORRECT claims\n"
            "4. Use ‚ö†Ô∏è emoji for PARTIALLY TRUE/MISLEADING claims\n"
            "5. DO NOT use bullet points (‚Ä¢) or asterisks (*) - Telegram doesn't support them well\n"
            "6. Add blank lines between paragraphs for readability\n\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "PART 1: SUMMARY (VERY SHORT - Mobile Display)\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "IMPORTANT: Keep this section VERY SHORT (max 500 words)\n"
            f"Format EXACTLY like this:\n\n"
            f"{overall_status_label} [‚úÖ/‚ö†Ô∏è/‚ùå]\n\n"
            f"{comparison_table_label}\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            f"{text_claim_label} 17%\n"
            f"{research_label} 17.1%\n"
            f"{conclusion_label} {example_conclusion1}\n"
            f"{status_label} ‚úÖ\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            f"{text_claim_label} 45%\n"
            f"{research_label} {example_not_specified}\n"
            f"{conclusion_label} {example_conclusion2}\n"
            f"{status_label} ‚ö†Ô∏è\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "(Continue for MAX 3-4 claims - each claim MUST be different!)\n\n"
            f"{result_label}\n"
            "[2-3 sentences ONLY]\n\n"
            "|||SPLIT|||\n\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "PART 2: DETAILED ANALYSIS (Complete)\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "CRITICAL: Add blank line between EVERY paragraph for readability!\n"
            "DO NOT use bullet points (‚Ä¢) or asterisks (*)\n"
            "Use simple numbered lists or plain paragraphs\n\n"
            "For each claim:\n"
            "- Full scientific explanation\n"
            "- Exact references with titles and links\n"
            "- Biological/technical mechanisms\n"
            "- Detailed comparison of ALL claimed vs actual data\n"
            "- Academic sources with DOI/URLs\n\n"
            f"Text to analyze:\n{text}"
        )
        
        chain = get_smart_chain()
        logger.info("üöÄ Invoking LangChain...")
        
        # Add callback for live model name updates
        config = {}
        if status_msg:
            config["callbacks"] = [StatusUpdateCallback(status_msg, get_msg)]
        
        # Invoke Chain (Async) with callbacks
        response = await chain.ainvoke([HumanMessage(content=prompt_text)], config=config)
        
        # Final status update with actual model name
        if status_msg:
            model_raw = response.response_metadata.get('model_name', 'gemini-2.5-flash')
            if "token_usage" in response.response_metadata:
                model_raw = "deepseek-chat"
            
            # Use model_raw directly (exact model name like "gemini-2.5-flash")
            model_name = model_raw
            
            try:
                await status_msg.edit_text(
                    f"‚úÖ **ÿ™ÿ≠ŸÑ€åŸÑ ÿ™Ÿàÿ≥ÿ∑ {model_name} ⁄©ÿßŸÖŸÑ ÿ¥ÿØ**\n(ÿØÿ± ÿ≠ÿßŸÑ ÿ¢ŸÖÿßÿØŸá‚Äåÿ≥ÿßÿ≤€å Ÿæÿßÿ≥ÿÆ...)",
                    parse_mode='Markdown'
                )
            except Exception:
                pass
        
        logger.info(f"‚úÖ Response from {model_name}")
        return response

    except Exception as e:
        logger.error(f"‚ùå SmartChain Error: {e}", exc_info=True)
        return None

# 4. Localization Dictionary
# 4. Localization Dictionary
MESSAGES = {
    "fa": {
        "welcome": (
            "üëã **ÿ≥ŸÑÿßŸÖ {name}!**\n"
            "ÿ®Ÿá **Su6i Yar**ÿå ÿØÿ≥ÿ™€åÿßÿ± ŸáŸàÿ¥ŸÖŸÜÿØ ÿÆŸàÿ¥ ÿ¢ŸÖÿØ€åÿØ.\n\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üîª ÿßÿ≤ ŸÖŸÜŸà€å Ÿæÿß€å€åŸÜ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ €åÿß ŸÑ€åŸÜ⁄© ÿ®ŸÅÿ±ÿ≥ÿ™€åÿØ"
        ),
        "btn_status": "üìä Ÿàÿ∂ÿπ€åÿ™ ÿ±ÿ®ÿßÿ™",
        "btn_help": "üÜò ÿ±ÿßŸáŸÜŸÖÿß",
        "btn_dl": "üì• ŸÖÿØ€åÿ±€åÿ™ ÿØÿßŸÜŸÑŸàÿØ",
        "btn_fc": "üß† ŸÖÿØ€åÿ±€åÿ™ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å",
        "btn_stop": "üõë ÿÆÿßŸÖŸàÿ¥ ⁄©ÿ±ÿØŸÜ ÿ±ÿ®ÿßÿ™",
        "btn_voice": "üîä ÿµŸàÿ™€å",
        "btn_lang_fa": "üáÆüá∑ ŸÅÿßÿ±ÿ≥€å",
        "btn_lang_en": "üá∫üá∏ English",
        "btn_lang_fr": "üá´üá∑ Fran√ßais",
        "status_fmt": (
            "üìä **Ÿàÿ∂ÿπ€åÿ™ ŸÑÿ≠ÿ∏Ÿá‚Äåÿß€å ÿ≥€åÿ≥ÿ™ŸÖ**\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üì• **ÿØÿßŸÜŸÑŸàÿØÿ±:**          {dl}\n"
            "üß† **ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å:**      {fc}\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üîª ÿ®ÿ±ÿß€å ÿ™ÿ∫€å€åÿ± ÿßÿ≤ ÿØ⁄©ŸÖŸá‚ÄåŸáÿß€å ÿ≤€åÿ± ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ"
        ),
        "help_msg": (
            "üìö **ÿ±ÿßŸáŸÜŸÖÿß€å ⁄©ÿßŸÖŸÑ ÿ±ÿ®ÿßÿ™**\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
            "üì• **ÿØÿßŸÜŸÑŸàÿØÿ± ÿß€åŸÜÿ≥ÿ™ÿß⁄Øÿ±ÿßŸÖ:**\n"
            "   ‚Ä¢ ŸÑ€åŸÜ⁄© Ÿæÿ≥ÿ™ €åÿß ÿ±€åŸÑÿ≤ ÿ®ŸÅÿ±ÿ≥ÿ™€åÿØ\n"
            "   ‚Ä¢ ÿØÿßŸÜŸÑŸàÿØ ÿÆŸàÿØ⁄©ÿßÿ± ÿ®ÿß ÿ®ÿßŸÑÿßÿ™ÿ±€åŸÜ ⁄©€åŸÅ€åÿ™\n\n"
            "üß† **ÿ™ÿ≠ŸÑ€åŸÑ ŸÖÿ™ŸÜ (/check):**\n"
            "   ‚Ä¢ ÿ®Ÿá €å⁄© Ÿæ€åÿßŸÖ ÿ±€åŸæŸÑÿß€å ⁄©ŸÜ€åÿØ: /check\n"
            "   ‚Ä¢ €åÿß ŸÖÿ≥ÿ™ŸÇ€åŸÖ ÿ®ŸÜŸà€åÿ≥€åÿØ: /check ŸÖÿ™ŸÜ\n"
            "   ‚Ä¢ ÿ™ÿ≠ŸÑ€åŸÑ ÿ®ÿß ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å + ⁄ØŸà⁄ØŸÑ\n\n"
            "üîä **ÿµŸàÿ™€å ⁄©ÿ±ÿØŸÜ (/voice):**\n"
            "   ‚Ä¢ ÿ®Ÿá Ÿæ€åÿßŸÖ ÿ±€åŸæŸÑÿß€å ⁄©ŸÜ€åÿØ: /voice\n"
            "   ‚Ä¢ €åÿß ŸÖÿ≥ÿ™ŸÇ€åŸÖ: /voice ŸÖÿ™ŸÜ\n"
            "   ‚Ä¢ ÿ™ÿ±ÿ¨ŸÖŸá + ÿµŸàÿ™€å: /voice en ŸÖÿ™ŸÜ\n"
            "   ‚Ä¢ ÿ≤ÿ®ÿßŸÜ‚ÄåŸáÿß: fa, en, fr, ko (kr)\n\n"
            "üìÑ **ÿ¨ÿ≤ÿ¶€åÿßÿ™ ÿ™ÿ≠ŸÑ€åŸÑ:**\n"
            "   ‚Ä¢ /detail - ÿØÿ±€åÿßŸÅÿ™ ÿ™ÿ≠ŸÑ€åŸÑ ⁄©ÿßŸÖŸÑ\n\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
        ),
        "dl_on": "‚úÖ ŸÅÿπÿßŸÑ",
        "dl_off": "‚ùå ÿ∫€åÿ±ŸÅÿπÿßŸÑ",
        "fc_on": "‚úÖ ŸÅÿπÿßŸÑ",
        "fc_off": "‚ùå ÿ∫€åÿ±ŸÅÿπÿßŸÑ",
        "action_dl": "üì• Ÿàÿ∂ÿπ€åÿ™ ÿØÿßŸÜŸÑŸàÿØ: {state}",
        "action_fc": "üß† Ÿàÿ∂ÿπ€åÿ™ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å: {state}",
        "lang_set": "üáÆüá∑ ÿ≤ÿ®ÿßŸÜ ÿ±Ÿà€å **ŸÅÿßÿ±ÿ≥€å** ÿ™ŸÜÿ∏€åŸÖ ÿ¥ÿØ",
        "menu_closed": "‚ùå ŸÖŸÜŸà ÿ®ÿ≥ÿ™Ÿá ÿ¥ÿØ. ÿ®ÿ±ÿß€å ÿ®ÿßÿ≤ ⁄©ÿ±ÿØŸÜ /start ÿ®ÿ≤ŸÜ€åÿØ",
        "only_admin": "‚õî ŸÅŸÇÿ∑ ÿßÿØŸÖ€åŸÜ ŸÖ€å‚Äåÿ™ŸàÿßŸÜÿØ ÿß€åŸÜ ⁄©ÿßÿ± ÿ±ÿß ÿßŸÜÿ¨ÿßŸÖ ÿØŸáÿØ",
        "bot_stop": "üõë ÿ±ÿ®ÿßÿ™ ÿØÿ± ÿ≠ÿßŸÑ ÿÆÿßŸÖŸàÿ¥ ÿ¥ÿØŸÜ...",
        "analyzing": "üß† ÿØÿ± ÿ≠ÿßŸÑ ÿ™ÿ≠ŸÑ€åŸÑ ÿπŸÑŸÖ€å...",
        "too_short": "‚ö†Ô∏è ŸÖÿ™ŸÜ ÿ®ÿ±ÿß€å ÿ™ÿ≠ŸÑ€åŸÑ ÿÆ€åŸÑ€å ⁄©Ÿàÿ™ÿßŸá ÿßÿ≥ÿ™",
        "downloading": "üì• ÿØÿ± ÿ≠ÿßŸÑ ÿØÿßŸÜŸÑŸàÿØ... ŸÑÿ∑ŸÅÿßŸã ÿµÿ®ÿ± ⁄©ŸÜ€åÿØ",
        "uploading": "üì§ ÿØÿ± ÿ≠ÿßŸÑ ÿ¢ŸæŸÑŸàÿØ ÿ®Ÿá ÿ™ŸÑ⁄Øÿ±ÿßŸÖ...",
        "err_dl": "‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿØÿßŸÜŸÑŸàÿØ. ŸÑ€åŸÜ⁄© ÿ±ÿß ÿ®ÿ±ÿ±ÿ≥€å ⁄©ŸÜ€åÿØ",
        "err_api": "‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿßÿ±ÿ™ÿ®ÿßÿ∑ ÿ®ÿß ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å. ÿ®ÿπÿØÿßŸã ÿ™ŸÑÿßÿ¥ ⁄©ŸÜ€åÿØ",
        "voice_generating": "üîä ÿØÿ± ÿ≠ÿßŸÑ ÿ≥ÿßÿÆÿ™ ŸÅÿß€åŸÑ ÿµŸàÿ™€å...",
        "voice_translating": "üåê ÿØÿ± ÿ≠ÿßŸÑ ÿ™ÿ±ÿ¨ŸÖŸá ÿ®Ÿá {lang}...",
        "voice_caption": "üîä ŸÜÿ≥ÿÆŸá ÿµŸàÿ™€å",
        "voice_caption_lang": "üîä ŸÜÿ≥ÿÆŸá ÿµŸàÿ™€å ({lang})",
        "voice_error": "‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿ≥ÿßÿÆÿ™ ŸÅÿß€åŸÑ ÿµŸàÿ™€å",
        "voice_no_text": "‚õî ÿ®Ÿá €å⁄© Ÿæ€åÿßŸÖ ÿ±€åŸæŸÑÿß€å ÿ®ÿ≤ŸÜ€åÿØ €åÿß ÿßÿ®ÿ™ÿØÿß €å⁄© ŸÖÿ™ŸÜ ÿ±ÿß ÿ™ÿ≠ŸÑ€åŸÑ ⁄©ŸÜ€åÿØ.",
        "voice_invalid_lang": "‚õî ÿ≤ÿ®ÿßŸÜ ŸÜÿßŸÖÿπÿ™ÿ®ÿ±. ÿ≤ÿ®ÿßŸÜ‚ÄåŸáÿß€å Ÿæÿ¥ÿ™€åÿ®ÿßŸÜ€å: fa, en, fr, ko",
        "access_denied": "‚õî ÿ¥ŸÖÿß ÿØÿ≥ÿ™ÿ±ÿ≥€å ÿ®Ÿá ÿß€åŸÜ ÿ±ÿ®ÿßÿ™ ŸÜÿØÿßÿ±€åÿØ.",
        "limit_reached": "‚õî ÿ≥ŸÇŸÅ ÿØÿ±ÿÆŸàÿßÿ≥ÿ™ ÿ±Ÿàÿ≤ÿßŸÜŸá ÿ¥ŸÖÿß ÿ™ŸÖÿßŸÖ ÿ¥ÿØ ({remaining} ÿßÿ≤ {limit}).",
        "remaining_requests": "üìä ÿØÿ±ÿÆŸàÿßÿ≥ÿ™‚ÄåŸáÿß€å ÿ®ÿßŸÇ€å‚ÄåŸÖÿßŸÜÿØŸá ÿßŸÖÿ±Ÿàÿ≤: {remaining}"
    },
    "en": {
        "welcome": (
            "üëã **Hello {name}!**\n"
            "Welcome to **Su6i Yar**, your AI assistant.\n\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üîª Use the menu below or send a link"
        ),
        "btn_status": "üìä Status",
        "btn_help": "üÜò Help",
        "btn_dl": "üì• Toggle Download",
        "btn_fc": "üß† Toggle AI",
        "btn_stop": "üõë Stop Bot",
        "btn_voice": "üîä Voice",
        "btn_lang_fa": "üáÆüá∑ ŸÅÿßÿ±ÿ≥€å",
        "btn_lang_en": "üá∫üá∏ English",
        "btn_lang_fr": "üá´üá∑ Fran√ßais",
        "status_fmt": (
            "üìä **Live System Status**\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üì• **Downloader:**       {dl}\n"
            "üß† **AI Fact-Check:**    {fc}\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üîª Use buttons below to toggle"
        ),
        "help_msg": (
            "üìö **Complete Bot Guide**\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
            "üì• **Instagram Downloader:**\n"
            "   ‚Ä¢ Send Post/Reels link\n"
            "   ‚Ä¢ Auto-download in highest quality\n\n"
            "üß† **Text Analysis (/check):**\n"
            "   ‚Ä¢ Reply to a message: /check\n"
            "   ‚Ä¢ Or directly: /check your text\n"
            "   ‚Ä¢ AI analysis + Google search\n\n"
            "üîä **Voice Conversion (/voice):**\n"
            "   ‚Ä¢ Reply to message: /voice\n"
            "   ‚Ä¢ Or directly: /voice text\n"
            "   ‚Ä¢ Translate + speak: /voice fa text\n"
            "   ‚Ä¢ Languages: fa, en, fr, ko (kr)\n\n"
            "üìÑ **Analysis Details:**\n"
            "   ‚Ä¢ /detail - Get full analysis\n\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
        ),
        "dl_on": "‚úÖ Active",
        "dl_off": "‚ùå Inactive",
        "fc_on": "‚úÖ Active",
        "fc_off": "‚ùå Inactive",
        "action_dl": "üì• Download status: {state}",
        "action_fc": "üß† AI status: {state}",
        "lang_set": "üá∫üá∏ Language set to **English**",
        "menu_closed": "‚ùå Menu closed. Type /start to reopen",
        "only_admin": "‚õî Admin only",
        "bot_stop": "üõë Bot is shutting down...",
        "analyzing": "üß† Analyzing...",
        "too_short": "‚ö†Ô∏è Text is too short to analyze",
        "downloading": "üì• Downloading... Please wait",
        "uploading": "üì§ Uploading to Telegram...",
        "err_dl": "‚ùå Download failed. Check the link",
        "err_api": "‚ùå AI API error. Try again later",
        "voice_generating": "üîä Generating audio...",
        "voice_translating": "üåê Translating to {lang}...",
        "voice_caption": "üîä Voice version",
        "voice_caption_lang": "üîä Voice version ({lang})",
        "voice_error": "‚ùå Error generating audio",
        "voice_no_text": "‚õî Reply to a message or analyze text first.",
        "voice_invalid_lang": "‚õî Invalid language. Supported: fa, en, fr, ko",
        "access_denied": "‚õî You don't have access to this bot.",
        "limit_reached": "‚õî Daily limit reached ({remaining} of {limit}).",
        "remaining_requests": "üìä Remaining requests today: {remaining}"
    },
    "fr": {
        "welcome": (
            "üëã **Bonjour {name}!**\n"
            "Bienvenue sur **Su6i Yar**, votre assistant IA.\n\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üîª Utilisez le menu ou envoyez un lien"
        ),
        "btn_status": "üìä √âtat",
        "btn_help": "üÜò Aide",
        "btn_dl": "üì• T√©l√©chargement",
        "btn_fc": "üß† IA",
        "btn_stop": "üõë Arr√™ter",
        "btn_voice": "üîä Voix",
        "btn_lang_fa": "üáÆüá∑ ŸÅÿßÿ±ÿ≥€å",
        "btn_lang_en": "üá∫üá∏ English",
        "btn_lang_fr": "üá´üá∑ Fran√ßais",
        "status_fmt": (
            "üìä **√âtat du Syst√®me**\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üì• **T√©l√©chargeur:**     {dl}\n"
            "üß† **IA Fact-Check:**    {fc}\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üîª Utilisez les boutons pour changer"
        ),
        "help_msg": (
            "üìö **Guide Complet du Bot**\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
            "üì• **T√©l√©chargeur Instagram:**\n"
            "   ‚Ä¢ Envoyez un lien Post/Reels\n"
            "   ‚Ä¢ T√©l√©chargement auto en HD\n\n"
            "üß† **Analyse Texte (/check):**\n"
            "   ‚Ä¢ R√©pondez √† un message: /check\n"
            "   ‚Ä¢ Ou directement: /check texte\n"
            "   ‚Ä¢ Analyse IA + recherche Google\n\n"
            "üîä **Conversion Audio (/voice):**\n"
            "   ‚Ä¢ R√©pondez au message: /voice\n"
            "   ‚Ä¢ Ou directement: /voice texte\n"
            "   ‚Ä¢ Traduire + parler: /voice fa texte\n"
            "   ‚Ä¢ Langues: fa, en, fr, ko (kr)\n\n"
            "üìÑ **D√©tails Analyse:**\n"
            "   ‚Ä¢ /detail - Analyse compl√®te\n\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
        ),
        "dl_on": "‚úÖ Actif",
        "dl_off": "‚ùå Inactif",
        "fc_on": "‚úÖ Actif",
        "fc_off": "‚ùå Inactif",
        "action_dl": "üì• T√©l√©chargement: {state}",
        "action_fc": "üß† IA: {state}",
        "lang_set": "üá´üá∑ Langue d√©finie sur **Fran√ßais**",
        "menu_closed": "‚ùå Menu ferm√©. Tapez /start",
        "only_admin": "‚õî Admin seulement",
        "bot_stop": "üõë Arr√™t du bot...",
        "analyzing": "üß† Analyse...",
        "too_short": "‚ö†Ô∏è Texte trop court pour analyser",
        "downloading": "üì• T√©l√©chargement... Patientez",
        "uploading": "üì§ Envoi vers Telegram...",
        "err_dl": "‚ùå √âchec du t√©l√©chargement. V√©rifiez le lien",
        "err_api": "‚ùå Erreur API IA. R√©essayez plus tard",
        "voice_generating": "üîä G√©n√©ration audio...",
        "voice_translating": "üåê Traduction en {lang}...",
        "voice_caption": "üîä Version audio",
        "voice_caption_lang": "üîä Version audio ({lang})",
        "voice_error": "‚ùå Erreur de g√©n√©ration audio",
        "voice_no_text": "‚õî R√©pondez √† un message ou analysez d'abord.",
        "voice_invalid_lang": "‚õî Langue invalide. Support√©es: fa, en, fr, ko",
        "access_denied": "‚õî Vous n'avez pas acc√®s √† ce bot.",
        "limit_reached": "‚õî Limite quotidienne atteinte ({remaining} sur {limit}).",
        "remaining_requests": "üìä Requ√™tes restantes aujourd'hui: {remaining}"
    },
    "ko": {
        "welcome": (
            "üëã **ÏïàÎÖïÌïòÏÑ∏Ïöî {name}!**\n"
            "**Su6i Yar**, AI ÎπÑÏÑúÏóê Ïò§Ïã† Í≤ÉÏùÑ ÌôòÏòÅÌï©ÎãàÎã§.\n\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üîª ÏïÑÎûò Î©îÎâ¥Î•º ÏÇ¨Ïö©ÌïòÍ±∞ÎÇò ÎßÅÌÅ¨Î•º Î≥¥ÎÇ¥ÏÑ∏Ïöî"
        ),
        "btn_status": "üìä ÏÉÅÌÉú",
        "btn_help": "üÜò ÎèÑÏõÄÎßê",
        "btn_dl": "üì• Îã§Ïö¥Î°úÎìú",
        "btn_fc": "üß† AI",
        "btn_stop": "üõë Ï§ëÏßÄ",
        "btn_voice": "üîä ÏùåÏÑ±",
        "btn_lang_fa": "üáÆüá∑ ŸÅÿßÿ±ÿ≥€å",
        "btn_lang_en": "üá∫üá∏ English",
        "btn_lang_fr": "üá´üá∑ Fran√ßais",
        "btn_lang_ko": "üá∞üá∑ ÌïúÍµ≠Ïñ¥",
        "status_fmt": (
            "üìä **ÏãúÏä§ÌÖú ÏÉÅÌÉú**\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üì• **Îã§Ïö¥Î°úÎçî:**     {dl}\n"
            "üß† **AI Ìå©Ìä∏Ï≤¥ÌÅ¨:**  {fc}\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üîª Î≤ÑÌäºÏùÑ ÎàåÎü¨ Î≥ÄÍ≤ΩÌïòÏÑ∏Ïöî"
        ),
        "help_msg": (
            "üìö **Î¥á Í∞ÄÏù¥Îìú**\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
            "üì• **Ïù∏Ïä§ÌÉÄÍ∑∏Îû® Îã§Ïö¥Î°úÎçî:**\n"
            "   ‚Ä¢ Ìè¨Ïä§Ìä∏/Î¶¥Ïä§ ÎßÅÌÅ¨ Ï†ÑÏÜ°\n"
            "   ‚Ä¢ ÏµúÍ≥† ÌôîÏßà ÏûêÎèô Îã§Ïö¥Î°úÎìú\n\n"
            "üß† **ÌÖçÏä§Ìä∏ Î∂ÑÏÑù (/check):**\n"
            "   ‚Ä¢ Î©îÏãúÏßÄÏóê ÎãµÏû•: /check\n"
            "   ‚Ä¢ ÎòêÎäî ÏßÅÏ†ë: /check ÌÖçÏä§Ìä∏\n"
            "   ‚Ä¢ AI Î∂ÑÏÑù + Íµ¨Í∏Ä Í≤ÄÏÉâ\n\n"
            "üîä **ÏùåÏÑ± Î≥ÄÌôò (/voice):**\n"
            "   ‚Ä¢ Î©îÏãúÏßÄÏóê ÎãµÏû•: /voice\n"
            "   ‚Ä¢ ÎòêÎäî ÏßÅÏ†ë: /voice ÌÖçÏä§Ìä∏\n"
            "   ‚Ä¢ Î≤àÏó≠ + ÎßêÌïòÍ∏∞: /voice fa ÌÖçÏä§Ìä∏\n"
            "   ‚Ä¢ Ïñ∏Ïñ¥: fa, en, fr, ko (kr)\n\n"
            "üìÑ **Î∂ÑÏÑù ÏÉÅÏÑ∏:**\n"
            "   ‚Ä¢ /detail - Ï†ÑÏ≤¥ Î∂ÑÏÑù\n\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
        ),
        "dl_on": "‚úÖ ÌôúÏÑ±Ìôî",
        "dl_off": "‚ùå ÎπÑÌôúÏÑ±Ìôî",
        "fc_on": "‚úÖ ÌôúÏÑ±Ìôî",
        "fc_off": "‚ùå ÎπÑÌôúÏÑ±Ìôî",
        "action_dl": "üì• Îã§Ïö¥Î°úÎìú ÏÉÅÌÉú: {state}",
        "action_fc": "üß† AI ÏÉÅÌÉú: {state}",
        "lang_set": "üá∞üá∑ **ÌïúÍµ≠Ïñ¥**Î°ú ÏÑ§Ï†ïÎêòÏóàÏäµÎãàÎã§",
        "menu_closed": "‚ùå Î©îÎâ¥Í∞Ä Îã´ÌòîÏäµÎãàÎã§. /startÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî",
        "only_admin": "‚õî Í¥ÄÎ¶¨Ïûê Ï†ÑÏö©",
        "bot_stop": "üõë Î¥áÏùÑ Ï§ëÏßÄÌï©ÎãàÎã§...",
        "analyzing": "üß† Î∂ÑÏÑù Ï§ë...",
        "too_short": "‚ö†Ô∏è Î∂ÑÏÑùÌïòÍ∏∞Ïóê ÌÖçÏä§Ìä∏Í∞Ä ÎÑàÎ¨¥ ÏßßÏäµÎãàÎã§",
        "downloading": "üì• Îã§Ïö¥Î°úÎìú Ï§ë... Ïû†ÏãúÎßå Í∏∞Îã§Î†§Ï£ºÏÑ∏Ïöî",
        "uploading": "üì§ ÌÖîÎ†àÍ∑∏Îû®Ïóê ÏóÖÎ°úÎìú Ï§ë...",
        "err_dl": "‚ùå Îã§Ïö¥Î°úÎìú Ïã§Ìå®. ÎßÅÌÅ¨Î•º ÌôïÏù∏ÌïòÏÑ∏Ïöî",
        "err_api": "‚ùå AI API Ïò§Î•ò. ÎÇòÏ§ëÏóê Îã§Ïãú ÏãúÎèÑÌïòÏÑ∏Ïöî",
        "voice_generating": "üîä Ïò§ÎîîÏò§ ÏÉùÏÑ± Ï§ë...",
        "voice_translating": "üåê {lang}Ïóê Î≤àÏó≠ Ï§ë...",
        "voice_caption": "üîä ÏùåÏÑ± Î≤ÑÏ†Ñ",
        "voice_caption_lang": "üîä ÏùåÏÑ± Î≤ÑÏ†Ñ ({lang})",
        "voice_error": "‚ùå Ïò§ÎîîÏò§ ÏÉùÏÑ± Ïò§Î•ò",
        "voice_no_text": "‚õî Î©îÏãúÏßÄÏóê ÎãµÏû•ÌïòÍ±∞ÎÇò Î®ºÏ†Ä ÌÖçÏä§Ìä∏Î•º Î∂ÑÏÑùÌïòÏÑ∏Ïöî.",
        "voice_invalid_lang": "‚õî ÏßÄÏõêÎêòÎäî Ïñ∏Ïñ¥: fa, en, fr, ko",
        "access_denied": "‚õî Ïù¥ Î¥áÏóê Ï†ëÍ∑º Í∂åÌïúÏù¥ ÏóÜÏäµÎãàÎã§.",
        "limit_reached": "‚õî ÏùºÏùº ÌïúÎèÑÏóê ÎèÑÎã¨ÌñàÏäµÎãàÎã§ ({remaining}/{limit}).",
        "remaining_requests": "üìä Ïò§Îäò ÎÇ®ÏùÄ ÏöîÏ≤≠: {remaining}"
    }
}

def get_msg(key, user_id=None):
    """Retrieve localized message based on User ID or Global Settings"""
    lang = "fa"
    if user_id and user_id in USER_LANG:
        lang = USER_LANG[user_id]
        # logger.info(f"DEBUG: Found User {user_id} Lang: {lang}") # Debug
    else:
        lang = SETTINGS.get("lang", "fa")
    
    # Validation
    if lang not in MESSAGES: lang = "fa"
    
    return MESSAGES.get(lang, MESSAGES["en"]).get(key, MESSAGES["en"].get(key, ""))

# ==============================================================================
# LOGIC: MENU & KEYBOARDS
# ==============================================================================

def get_main_keyboard(user_id):
    """Generate the dynamic keyboard based on User Language"""
    is_admin = user_id == SETTINGS["admin_id"]
    
    # Base keyboard for all users
    kb = [
        [KeyboardButton(get_msg("btn_status", user_id)), KeyboardButton(get_msg("btn_help", user_id)), KeyboardButton(get_msg("btn_voice", user_id))],
        [KeyboardButton("üáÆüá∑ ŸÅÿßÿ±ÿ≥€å"), KeyboardButton("üá∫üá∏ English"), KeyboardButton("üá´üá∑ Fran√ßais"), KeyboardButton("üá∞üá∑ ÌïúÍµ≠Ïñ¥")]
    ]
    
    # Admin-only: Settings row
    if is_admin:
        kb.insert(1, [KeyboardButton(get_msg("btn_dl", user_id)), KeyboardButton(get_msg("btn_fc", user_id)), KeyboardButton(get_msg("btn_stop", user_id))])
    
    return ReplyKeyboardMarkup(kb, resize_keyboard=True)

async def send_welcome(update: Update):
    """Send welcome message with menu"""
    user = update.effective_user
    text = get_msg("welcome", user.id).format(name=user.first_name)
    await update.message.reply_text(
        text, 
        parse_mode='Markdown',
        reply_markup=get_main_keyboard(user.id)
    )





# ==============================================================================
# HELPERS
# ==============================================================================

async def smart_reply(msg, status_msg, response, user_id):
    """Send AI response with formatted model name and /detail instruction"""
    if not response:
        await status_msg.edit_text(get_msg("err_api", user_id))
        return

    # 1. Format Model Name
    model_raw = response.response_metadata.get("model_name", "gemini-2.5-flash")
    if "token_usage" in response.response_metadata:
        model_raw = "deepseek-chat"
    
    model_map = {
        "gemini-2.5-pro": "Gemini 2.5 Pro",
        "gemini-1.5-pro": "Gemini 1.5 Pro",
        "gemini-2.5-flash": "Gemini 2.5 Flash",
        "gemini-2.0-flash": "Gemini 2.0 Flash",
        "gemini-1.5-flash": "Gemini 1.5 Flash",
        "gemini-1.5-flash-8b": "Gemini 1.5 Flash 8B",
        "deepseek-chat": "DeepSeek Chat"
    }
    model_name = model_map.get(model_raw, model_raw.replace("-", " ").title())
    
    # 2. Get user language for header/footer
    lang = USER_LANG.get(user_id, "fa")
    
    header_templates = {
        "fa": "üß† **ÿ™ÿ≠ŸÑ€åŸÑ ÿ™Ÿàÿ≥ÿ∑ {}**",
        "en": "üß† **Analysis by {}**",
        "fr": "üß† **Analyse par {}"
    }
    
    footer_templates = {
        "fa": (
            "\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üí° **ÿ®ÿ±ÿß€å ŸÖÿ¥ÿßŸáÿØŸá ÿ™ÿ≠ŸÑ€åŸÑ ⁄©ÿßŸÖŸÑ:**\n"
            "ÿ®Ÿá ÿß€åŸÜ Ÿæ€åÿßŸÖ ÿ±€åŸæŸÑÿß€å ÿ®ÿ≤ŸÜ€åÿØ Ÿà `/detail` ÿ®ŸÜŸà€åÿ≥€åÿØ"
        ),
        "en": (
            "\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üí° **For full analysis:**\n"
            "Reply to this message with `/detail`"
        ),
        "fr": (
            "\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üí° **Pour l'analyse compl√®te:**\n"
            "R√©pondez avec `/detail`"
        )
    }
    
    header = header_templates.get(lang, header_templates["fa"]).format(model_name)
    footer = footer_templates.get(lang, footer_templates["fa"])
    
    # 3. Parse Split (Summary vs Detail)
    full_content = response.content
    split_marker = "|||SPLIT|||"
    
    if split_marker in full_content:
        parts = full_content.split(split_marker, 1)
        summary_text = parts[0].strip()
        detail_text = parts[1].strip()
        
        # Cache detailed analysis
        LAST_ANALYSIS_CACHE[user_id] = f"{header}\n\n{detail_text}"
        logger.info(f"üíæ Cached {len(detail_text)} chars for user {user_id}")
    else:
        # No split found - send everything as summary
        logger.warning(f"‚ö†Ô∏è No split marker found in response")
        summary_text = full_content
        
        no_detail_msgs = {
            "fa": "‚ö†Ô∏è ÿ¨ÿ≤ÿ¶€åÿßÿ™ ÿ®€åÿ¥ÿ™ÿ±€å ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜ€åÿ≥ÿ™",
            "en": "‚ö†Ô∏è No additional details available",
            "fr": "‚ö†Ô∏è Aucun d√©tail suppl√©mentaire"
        }
        LAST_ANALYSIS_CACHE[user_id] = no_detail_msgs.get(lang, no_detail_msgs["fa"])

    # 4. Construct final message
    final_text = f"{header}\n\n{summary_text}{footer}"
    
    # 5. Send (with chunking if needed)
    max_length = 4000
    if len(final_text) > max_length:
        # Chunk the message
        chunks = [final_text[i:i+max_length] for i in range(0, len(final_text), max_length)]
        for i, chunk in enumerate(chunks):
            try:
                if i == 0:
                    await status_msg.edit_text(chunk, parse_mode='Markdown')
                else:
                    await msg.reply_text(chunk, parse_mode='Markdown')
            except Exception:
                # Fallback without Markdown
                if i == 0:
                    await status_msg.edit_text(chunk, parse_mode=None)
                else:
                    await msg.reply_text(chunk, parse_mode=None)
    else:
        # Normal case
        try:
            await status_msg.edit_text(final_text, parse_mode='Markdown')
        except Exception:
            await status_msg.edit_text(final_text, parse_mode=None)

# ==============================================================================
# LOGIC: INSTAGRAM DOWNLOAD
# ==============================================================================

async def download_instagram(url, chat_id, bot, reply_to_message_id=None):
    """Download and send video using yt-dlp"""
    try:
        # 1. Filename setup
        timestamp = int(asyncio.get_event_loop().time())
        filename = Path(f"insta_{timestamp}.mp4")
        
        # 2. Command
        cmd = [
            "yt-dlp",
            "-f", "best[ext=mp4]",
            "-o", str(filename),
            url
        ]
        
        # 3. Cookies if available
        cookie_file = Path("cookies.txt")
        if cookie_file.exists():
            cmd.insert(1, str(cookie_file))
            cmd.insert(1, "--cookies")

        # 4. Run Download
        process = await asyncio.create_subprocess_exec(
            *cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE
        )
        stdout, stderr = await process.communicate()
        
        if process.returncode != 0:
            logger.error(f"Download Error: {stderr.decode()}")
            return False

        # 5. Send to User
        if filename.exists():
            with open(filename, "rb") as video_file:
                await bot.send_video(
                    chat_id=chat_id,
                    video=video_file,
                    caption="üì• **Su6i Yar** | @su6i\\_yar\\_bot",
                    parse_mode='Markdown',
                    reply_to_message_id=reply_to_message_id,
                    supports_streaming=True
                )
            # Cleanup
            filename.unlink()
            return True
        return False
        
    except Exception as e:
        logger.error(f"DL Exception: {e}")
        return False

# ==============================================================================
# HANDLERS
# ==============================================================================

# ==============================================================================
# PROCESSED HANDLERS (DEBUGGING ADDED)
# ==============================================================================

async def cmd_start_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info(f"üöÄ Command /start triggered by {update.effective_user.id}")
    await send_welcome(update)

async def cmd_close_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info("‚ùå Command /close triggered")
    await update.message.reply_text(
        get_msg("menu_closed"), 
        reply_markup=ReplyKeyboardRemove()
    )

async def cmd_status_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info("üìä Command /status triggered")
    dl_s = get_msg("dl_on") if SETTINGS["download"] else get_msg("dl_off")
    fc_s = get_msg("fc_on") if SETTINGS["fact_check"] else get_msg("fc_off")
    info = get_msg("status_fmt").format(dl=dl_s, fc=fc_s)
    await update.message.reply_text(info, parse_mode='Markdown')

async def cmd_toggle_dl_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info("üì• Command /toggle_dl triggered")
    SETTINGS["download"] = not SETTINGS["download"]
    state = get_msg("dl_on") if SETTINGS["download"] else get_msg("dl_off")
    await update.message.reply_text(get_msg("action_dl").format(state=state))

async def cmd_toggle_fc_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info("üß† Command /toggle_fc triggered")
    SETTINGS["fact_check"] = not SETTINGS["fact_check"]
    state = get_msg("fc_on") if SETTINGS["fact_check"] else get_msg("fc_off")
    await update.message.reply_text(get_msg("action_fc").format(state=state))

async def cmd_stop_bot_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    if user_id != SETTINGS["admin_id"]:
        await update.message.reply_text(get_msg("only_admin"))
        return
    await update.message.reply_text(get_msg("bot_stop"), reply_markup=ReplyKeyboardRemove())
    logger.info("üõë KILLING PROCESS WITH SIGKILL (9)")
    os.kill(os.getpid(), signal.SIGKILL)

async def global_message_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """MASTER HANDLER: Processes ALL text messages"""
    msg = update.message
    if not msg or not msg.text: return
    text = msg.text.strip()
    user = update.effective_user
    user_id = user.id
    
    # Ensure User Lang
    if user_id not in USER_LANG:
        USER_LANG[user_id] = "fa"
    lang = USER_LANG[user_id]

    logger.info(f"üì® Message received: '{text}' from {user.id} ({lang})")

    # --- 1. MENU COMMANDS (Check by Emoji/Start) --- 
    
    # Status
    if text.startswith("üìä"):
        dl_s = get_msg("dl_on", user_id) if SETTINGS["download"] else get_msg("dl_off", user_id)
        fc_s = get_msg("fc_on", user_id) if SETTINGS["fact_check"] else get_msg("fc_off", user_id)
        info = get_msg("status_fmt", user_id).format(dl=dl_s, fc=fc_s)
        await msg.reply_text(info, parse_mode='Markdown')
        return

    # Language Switching
    if "ŸÅÿßÿ±ÿ≥€å" in text:
        USER_LANG[user_id] = "fa"
        await msg.reply_text("‚úÖ ÿ≤ÿ®ÿßŸÜ ŸÅÿßÿ±ÿ≥€å ÿßŸÜÿ™ÿÆÿßÿ® ÿ¥ÿØ.", reply_markup=get_main_keyboard(user_id))
        return
    if "English" in text:
        USER_LANG[user_id] = "en"
        await msg.reply_text("‚úÖ English language selected.", reply_markup=get_main_keyboard(user_id))
        logger.info(f"üá∫üá∏ User {user_id} switched to English")
        return
    if "Fran√ßais" in text:
        USER_LANG[user_id] = "fr"
        await msg.reply_text("‚úÖ Langue fran√ßaise s√©lectionn√©e.", reply_markup=get_main_keyboard(user_id))
        return
    if "ÌïúÍµ≠Ïñ¥" in text:
        USER_LANG[user_id] = "ko"
        await msg.reply_text("‚úÖ ÌïúÍµ≠Ïñ¥Í∞Ä ÏÑ†ÌÉùÎêòÏóàÏäµÎãàÎã§.", reply_markup=get_main_keyboard(user_id))
        return
    
    # Voice Button
    if text.startswith("üîä"):
        detail_text = LAST_ANALYSIS_CACHE.get(user_id)
        if not detail_text:
            await msg.reply_text("‚õî Ÿá€å⁄Ü ÿ™ÿ≠ŸÑ€åŸÑ ÿ∞ÿÆ€åÿ±Ÿá‚Äåÿ¥ÿØŸá‚Äåÿß€å ŸÖŸàÿ¨ŸàÿØ ŸÜ€åÿ≥ÿ™.")
            return
        status_msg = await msg.reply_text("üîä ÿØÿ± ÿ≠ÿßŸÑ ÿ≥ÿßÿÆÿ™ ŸÅÿß€åŸÑ ÿµŸàÿ™€å...")
        try:
            audio_buffer = await text_to_speech(detail_text, lang)
            await msg.reply_voice(voice=audio_buffer, caption="üîä ŸÜÿ≥ÿÆŸá ÿµŸàÿ™€å ÿ™ÿ≠ŸÑ€åŸÑ")
            await status_msg.delete()
        except Exception as e:
            logger.error(f"TTS Error: {e}")
            await status_msg.edit_text("‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿ≥ÿßÿÆÿ™ ŸÅÿß€åŸÑ ÿµŸàÿ™€å")
        return
        
    # Help
    if text.startswith("‚ÑπÔ∏è") or text.startswith("üÜò"):
        help_text = get_msg("help_msg", user_id)
        await msg.reply_text(help_text, parse_mode='Markdown') 
        return

    # Toggle DL
    if text.startswith("üì•"):
        SETTINGS["download"] = not SETTINGS["download"]
        state = get_msg("dl_on", user_id) if SETTINGS["download"] else get_msg("dl_off", user_id)
        await msg.reply_text(get_msg("action_dl", user_id).format(state=state))
        return

    # Toggle FC
    if text.startswith("üß†"):
        SETTINGS["fact_check"] = not SETTINGS["fact_check"]
        state = get_msg("fc_on", user_id) if SETTINGS["fact_check"] else get_msg("fc_off", user_id)
        await msg.reply_text(get_msg("action_fc", user_id).format(state=state))
        return

    # Stop (Button)
    if text.startswith("üõë") and user_id == SETTINGS["admin_id"]:
        logger.info("üõë Stop Button Triggered")
        await msg.reply_text(get_msg("bot_stop", user_id), reply_markup=ReplyKeyboardRemove())
        await asyncio.sleep(1)
        os.kill(os.getpid(), signal.SIGKILL)
        return

    # --- 2. INSTAGRAM LINK CHECK ---
    if "instagram.com" in text:
        if not SETTINGS["download"]:
            await msg.reply_text("‚ö†Ô∏è " + get_msg("dl_off", user_id))
            return
            
        status_msg = await msg.reply_text(get_msg("downloading", user_id))
        
        success = await download_instagram(text, msg.chat_id, context.bot, msg.message_id)
        if success:
            await status_msg.delete()
        else:
            await status_msg.edit_text(get_msg("err_dl", user_id))
        return

    # --- 3. AI ANALYSIS (Fallback) ---
    
    if SETTINGS["fact_check"] and len(text) >= SETTINGS["min_fc_len"]:
        # Access Control Check
        allowed, reason = check_access(user_id, msg.chat_id)
        if not allowed:
            await msg.reply_text(get_msg("access_denied", user_id))
            return
        
        # Daily Limit Check
        has_quota, remaining = check_daily_limit(user_id)
        if not has_quota:
            limit = get_user_limit(user_id)
            await msg.reply_text(get_msg("limit_reached", user_id).format(remaining=0, limit=limit))
            return
        
        status_msg = await msg.reply_text(
            get_msg("analyzing", user_id),
            reply_to_message_id=msg.message_id
        )
        response = await analyze_text_gemini(text, status_msg, lang)
        
        # Increment usage and get remaining
        remaining = increment_daily_usage(user_id)
        
        await smart_reply(msg, status_msg, response, user_id)
        
        # Show remaining requests (skip for admin)
        if user_id != SETTINGS["admin_id"]:
            limit = get_user_limit(user_id)
            await msg.reply_text(f"üìä {remaining}/{limit} ÿØÿ±ÿÆŸàÿßÿ≥ÿ™ ÿ®ÿßŸÇ€å‚ÄåŸÖÿßŸÜÿØŸá ÿßŸÖÿ±Ÿàÿ≤")
        return

# ==============================================================================
# MAIN EXECUTION
# ==============================================================================

async def cmd_detail_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Fetches the cached detailed analysis (Zero-Cost)"""
    logger.info("üîç Command /detail triggered")
    msg = update.message
    user_id = update.effective_user.id
    
    # Check Cache
    detail_text = LAST_ANALYSIS_CACHE.get(user_id)
    
    if not detail_text:
        await msg.reply_text("‚õî Ÿá€å⁄Ü ÿ™ÿ≠ŸÑ€åŸÑ ÿ∞ÿÆ€åÿ±Ÿá‚Äåÿ¥ÿØŸá‚Äåÿß€å ŸÖŸàÿ¨ŸàÿØ ŸÜ€åÿ≥ÿ™. ÿßÿ®ÿ™ÿØÿß €å⁄© ŸÖÿ™ŸÜ ÿ±ÿß ÿ™ÿ≠ŸÑ€åŸÑ ⁄©ŸÜ€åÿØ.")
        return

    # Smart chunking: split by paragraphs, not mid-paragraph
    max_length = 3900  # Leave some margin
    
    if len(detail_text) <= max_length:
        # Fits in one message
        try:
            await msg.reply_text(detail_text, parse_mode='Markdown')
        except Exception:
            await msg.reply_text(detail_text, parse_mode=None)
    else:
        # Need to chunk - split by paragraphs
        paragraphs = detail_text.split('\n\n')
        chunks = []
        current_chunk = ""
        
        for para in paragraphs:
            # If adding this paragraph exceeds limit, save current chunk and start new one
            if len(current_chunk) + len(para) + 2 > max_length:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = para
            else:
                if current_chunk:
                    current_chunk += "\n\n" + para
                else:
                    current_chunk = para
        
        # Don't forget the last chunk
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        # Send all chunks
        for i, chunk in enumerate(chunks):
            try:
                if i == 0:
                    await msg.reply_text(f"{chunk}\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nüìÑ ÿ®ÿÆÿ¥ {i+1} ÿßÿ≤ {len(chunks)}", parse_mode='Markdown')
                else:
                    await msg.reply_text(f"üìÑ ÿ®ÿÆÿ¥ {i+1} ÿßÿ≤ {len(chunks)}\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n{chunk}", parse_mode='Markdown')
            except Exception:
                if i == 0:
                    await msg.reply_text(f"{chunk}\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nüìÑ ÿ®ÿÆÿ¥ {i+1} ÿßÿ≤ {len(chunks)}", parse_mode=None)
                else:
                    await msg.reply_text(f"üìÑ ÿ®ÿÆÿ¥ {i+1} ÿßÿ≤ {len(chunks)}\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n{chunk}", parse_mode=None)


# TTS Voice Mapping
TTS_VOICES = {
    "fa": "fa-IR-FaridNeural",   # Persian - Male
    "en": "en-US-GuyNeural",     # English - Male
    "fr": "fr-FR-HenriNeural",   # French - Male
    "ko": "ko-KR-InJoonNeural"   # Korean - Male
}

async def text_to_speech(text: str, lang: str = "fa") -> io.BytesIO:
    """Convert text to speech using edge-tts. Returns audio as BytesIO."""
    voice = TTS_VOICES.get(lang, TTS_VOICES["fa"])
    
    # Clean text for TTS (remove markdown)
    clean_text = re.sub(r'\*\*|‚ñ´Ô∏è|‚îÅ+|‚úÖ|‚ùå|‚ö†Ô∏è|üß†|üìÑ|üí°', '', text)
    clean_text = re.sub(r'\[.*?\]', '', clean_text)  # Remove markdown links
    clean_text = clean_text.strip()
    
    # Limit length for TTS (avoid very long audio)
    if len(clean_text) > 2000:
        clean_text = clean_text[:2000] + "..."
    
    communicate = edge_tts.Communicate(clean_text, voice)
    audio_buffer = io.BytesIO()
    
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            audio_buffer.write(chunk["data"])
    
    audio_buffer.seek(0)
    return audio_buffer

# Language code mapping for /voice command
LANG_ALIASES = {
    "fa": "fa", "farsi": "fa", "persian": "fa", "ŸÅÿßÿ±ÿ≥€å": "fa",
    "en": "en", "english": "en", "ÿßŸÜ⁄ØŸÑ€åÿ≥€å": "en",
    "fr": "fr", "french": "fr", "fran√ßais": "fr", "ŸÅÿ±ÿßŸÜÿ≥Ÿà€å": "fr",
    "ko": "ko", "kr": "ko", "korean": "ko", "ÌïúÍµ≠Ïñ¥": "ko", "⁄©ÿ±Ÿá‚Äåÿß€å": "ko"
}

LANG_NAMES = {
    "fa": "Persian (Farsi)", "en": "English", "fr": "French", "ko": "Korean"
}

async def translate_text(text: str, target_lang: str) -> str:
    """Translate text to target language using Gemini"""
    lang_name = LANG_NAMES.get(target_lang, "English")
    
    try:
        chain = get_smart_chain()
        prompt = f"Translate the following text to {lang_name}. Only output the translation, no explanations:\n\n{text}"
        response = await chain.ainvoke([HumanMessage(content=prompt)])
        return response.content.strip()
    except Exception as e:
        logger.error(f"Translation error: {e}")
        return text  # Return original if translation fails


async def cmd_voice_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    Send voice version of replied message or last analysis.
    Usage: /voice [language]
    Examples: /voice, /voice en, /voice english, /voice ŸÅÿßÿ±ÿ≥€å
    """
    logger.info("üîä Command /voice triggered")
    msg = update.message
    user_id = update.effective_user.id
    user_lang = USER_LANG.get(user_id, "fa")
    
    # Check for language argument
    target_lang = user_lang  # Default to user's app language
    if context.args:
        lang_arg = context.args[0].lower()
        if lang_arg in LANG_ALIASES:
            target_lang = LANG_ALIASES[lang_arg]
        else:
            await msg.reply_text(get_msg("voice_invalid_lang", user_id))
            return
    
    # Priority 1: Check if replied to a message
    target_text = ""
    if msg.reply_to_message:
        logger.info(f"üîä Reply detected: text={bool(msg.reply_to_message.text)}, caption={bool(msg.reply_to_message.caption)}")
        target_text = msg.reply_to_message.text or msg.reply_to_message.caption or ""
    else:
        logger.info("üîä No reply_to_message detected")
    
    # Priority 2: Check for direct text input (/voice <text> or /voice <lang> <text>)
    if not target_text and context.args:
        # If first arg is a language code, text starts from arg[1]
        if context.args[0].lower() in LANG_ALIASES:
            if len(context.args) > 1:
                target_text = " ".join(context.args[1:])
                logger.info(f"üîä Using direct text after lang arg: {len(target_text)} chars")
        else:
            # First arg is text, not a language code
            target_text = " ".join(context.args)
            logger.info(f"üîä Using direct text: {len(target_text)} chars")
    
    # Priority 3: Check cache if no reply and no direct text
    if not target_text:
        target_text = LAST_ANALYSIS_CACHE.get(user_id, "")
        logger.info(f"üîä Using cache: {bool(target_text)}")
    
    if not target_text:
        logger.info("üîä No text found, sending error")
        await msg.reply_text(get_msg("voice_no_text", user_id))
        return
    
    # Check if translation is needed (if target_lang differs from user's default)
    need_translation = target_lang != user_lang
    
    if need_translation:
        status_msg = await msg.reply_text(get_msg("voice_translating", user_id).format(lang=LANG_NAMES.get(target_lang, target_lang)))
        target_text = await translate_text(target_text, target_lang)
        await status_msg.edit_text(get_msg("voice_generating", user_id))
    else:
        status_msg = await msg.reply_text(get_msg("voice_generating", user_id))
    
    try:
        audio_buffer = await text_to_speech(target_text, target_lang)
        # Reply to the original message (not the /voice command)
        reply_to_id = msg.reply_to_message.message_id if msg.reply_to_message else msg.message_id
        
        caption = get_msg("voice_caption_lang", user_id).format(lang=LANG_NAMES.get(target_lang, target_lang)) if need_translation else get_msg("voice_caption", user_id)
        await msg.reply_voice(
            voice=audio_buffer,
            caption=caption,
            reply_to_message_id=reply_to_id
        )
        await status_msg.delete()
    except Exception as e:
        logger.error(f"TTS Error: {e}")
        await status_msg.edit_text(get_msg("voice_error", user_id))


def main():
    if not TELEGRAM_TOKEN:
        print("‚ùå Error: TELEGRAM_BOT_TOKEN not found in .env")
        return

    print("üöÄ Starting SmartBot Core...")
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).concurrent_updates(True).build()

    # Commands
    app.add_handler(CommandHandler("start", cmd_start_handler))
    app.add_handler(CommandHandler("help", cmd_start_handler)) # Reuse start for help
    app.add_handler(CommandHandler("close", cmd_close_handler))
    app.add_handler(CommandHandler("status", cmd_status_handler))
    app.add_handler(CommandHandler("toggle_dl", cmd_toggle_dl_handler))
    app.add_handler(CommandHandler("toggle_fc", cmd_toggle_fc_handler))
    app.add_handler(CommandHandler("check", cmd_check_handler))
    app.add_handler(CommandHandler("detail", cmd_detail_handler))
    app.add_handler(CommandHandler("voice", cmd_voice_handler))  # TTS Voice
    app.add_handler(CommandHandler("stop", cmd_stop_bot_handler))

    # All Messages (Text)
    app.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), global_message_handler))

    print("‚úÖ Bot is Polling...")
    app.run_polling(
        allowed_updates=["message", "callback_query"],  # Only listen to needed updates
        drop_pending_updates=True,  # Ignore old messages on restart
        close_loop=False  # Allow graceful shutdown
    )

if __name__ == "__main__":
    main()
