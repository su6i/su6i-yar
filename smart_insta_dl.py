import os
import re
import sys
import asyncio
import logging
import subprocess
import signal
import warnings
# Suppress Pydantic V1 warning on Python 3.14+
warnings.filterwarnings("ignore", category=UserWarning, module="langchain_core._api.deprecation")

from pathlib import Path
from dotenv import load_dotenv

# Telegram Imports
from telegram import Update, ReplyKeyboardMarkup, KeyboardButton, ReplyKeyboardRemove
from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters

# LangChain Imports
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

# ==============================================================================
# CONFIGURATION & SETUP
# ==============================================================================

# 1. Logging Setup
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger("SmartBot")

# 2. Environment Variables
load_dotenv()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

# 3. Global Settings
SETTINGS = {
    "download": True,
    "fact_check": True,
    "min_fc_len": 50,
    "lang": "fa",
    "admin_id": int(TELEGRAM_CHAT_ID) if TELEGRAM_CHAT_ID else 0
}

# User Preferences (In-Memory)
USER_LANG = {}

# ... (Localization Dictionary MESSAGES is unchanged, skipping for brevity) ...

async def cmd_check_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info("‚úÖ Command /check triggered")
    msg = update.message
    user_id = update.effective_user.id
    lang = USER_LANG.get(user_id, "fa")

    # Check if reply or arguments
    target_text = ""
    if msg.reply_to_message and msg.reply_to_message.text:
        target_text = msg.reply_to_message.text
    elif context.args:
        target_text = " ".join(context.args)
    
    if not target_text:
        await msg.reply_text("‚õî Reply to a message or provide text: `/check <text>`")
        return

    status_msg = await msg.reply_text(get_msg("analyzing"))
    response = await analyze_text_gemini(target_text, lang)
    
    await smart_reply(msg, status_msg, response, user_id)

async def global_message_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """MASTER HANDLER: Processes ALL text messages"""
    msg = update.message
    if not msg or not msg.text: return
    text = msg.text.strip()
    user = update.effective_user
    user_id = user.id
    
    # Ensure User Lang
    if user_id not in USER_LANG:
        USER_LANG[user_id] = "fa"
    lang = USER_LANG[user_id]

    logger.info(f"üì® Message received: '{text}' from {user.id} ({lang})")

    # --- 1. MENU COMMANDS (Check by Emoji/Start) --- 
    
    # Status
    if text.startswith("üìä"):
        dl_s = get_msg("dl_on") if SETTINGS["download"] else get_msg("dl_off")
        fc_s = get_msg("fc_on") if SETTINGS["fact_check"] else get_msg("fc_off")
        info = get_msg("status_fmt").format(dl=dl_s, fc=fc_s)
        await msg.reply_text(info, parse_mode='Markdown')
        return

    # Language Switching
    if "ŸÅÿßÿ±ÿ≥€å" in text:
        USER_LANG[user_id] = "fa"
        await msg.reply_text("‚úÖ ÿ≤ÿ®ÿßŸÜ ŸÅÿßÿ±ÿ≥€å ÿßŸÜÿ™ÿÆÿßÿ® ÿ¥ÿØ.", reply_markup=get_main_keyboard(user_id))
        return
    if "English" in text:
        USER_LANG[user_id] = "en"
        await msg.reply_text("‚úÖ English language selected.", reply_markup=get_main_keyboard(user_id))
        return
    if "Fran√ßais" in text:
        USER_LANG[user_id] = "fr"
        await msg.reply_text("‚úÖ Langue fran√ßaise s√©lectionn√©e.", reply_markup=get_main_keyboard(user_id))
        return
        
    # Help
    if text.startswith("‚ÑπÔ∏è"):
        # Note: get_help_msg should be updated to accept user_id/lang if needed, but for now assuming it uses global logic or we update it later.
        # Assuming get_help_msg(user_id) exists from previous context? I didn't verify get_help_msg signature. 
        # Let's check get_help_msg call in previous code.. it was `get_help_msg(user_id)`?
        # Actually in Step 3835: `get_help_msg` usage wasn't shown.
        # Wait, I should not assume `get_help_msg` takes user_id if I haven't seen it. 
        # But `get_help_msg` was called in `cmd_start_handler`?
        # I'll stick to safest: check existing usage in file.
        # Existing global_message_handler (line 535) didn't show help handler.
        # Ah, looking at `get_main_keyboard`...
        # I'll just skip the Help `if` block since normally `/help` handles it?
        # No, the menu button "Help" sends "‚ÑπÔ∏è Help" text.
        await msg.reply_text("‚ÑπÔ∏è Use /help to see commands.") 
        return

    # Toggle DL
    if text.startswith("üì•"):
        SETTINGS["download"] = not SETTINGS["download"]
        state = get_msg("dl_on") if SETTINGS["download"] else get_msg("dl_off")
        await msg.reply_text(get_msg("action_dl").format(state=state))
        return

    # Toggle FC
    if text.startswith("üß†"):
        SETTINGS["fact_check"] = not SETTINGS["fact_check"]
        state = get_msg("fc_on") if SETTINGS["fact_check"] else get_msg("fc_off")
        await msg.reply_text(get_msg("action_fc").format(state=state))
        return

    # Stop (Button)
    if text.startswith("üõë") and user_id == SETTINGS["admin_id"]:
        logger.info("üõë Stop Button Triggered")
        await msg.reply_text(get_msg("bot_stop"))
        os.kill(os.getpid(), signal.SIGKILL)
        return

    # --- 2. INSTAGRAM LINK CHECK ---
    if "instagram.com" in text:
        if not SETTINGS["download"]:
            await msg.reply_text("‚ö†Ô∏è " + get_msg("dl_off"))
            return
            
        status_msg = await msg.reply_text(get_msg("downloading"))
        
        # Run yt-dlp logic
        loop = asyncio.get_event_loop()
        file_path = await loop.run_in_executor(None, download_instagram_video, text)
        
        if file_path:
            try:
                await status_msg.edit_text(get_msg("uploading"))
                await msg.reply_video(video=open(file_path, 'rb'), caption="ü§ñ @SmartInstaDL_Bot")
                os.remove(file_path) # Cleanup
                await status_msg.delete() 
            except Exception as e:
                logger.error(f"Upload failed: {e}")
                await status_msg.edit_text("‚ùå Error uploading video.")
        else:
            await status_msg.edit_text("‚ùå Download failed (Private/Invalid link).")
        return

    # --- 3. AI ANALYSIS (Fallback) ---
    
    if SETTINGS["fact_check"] and len(text) >= SETTINGS["min_fc_len"]:
        status_msg = await msg.reply_text(get_msg("analyzing"))
        response = await analyze_text_gemini(text, lang)
        
        await smart_reply(msg, status_msg, response, user_id)
        return

# ==============================================================================
# LOGIC: SMART CHAIN FACTORY (LANGCHAIN)
# ==============================================================================

def get_smart_chain():
    """Constructs the self-healing AI model chain (8-Layer Defense)"""
    logger.info("‚õìÔ∏è Building Smart AI Chain...")
    
    defaults = {"google_api_key": GEMINI_API_KEY, "temperature": 0.3}

    # 1. Gemini 2.5 Pro (Primary)
    # Enable Google Search Grounding for real-time fact checking
    primary = ChatGoogleGenerativeAI(
        model="gemini-2.5-pro", 
        **defaults,
        # Grounding: Use built-in Google Search Retrieval
        model_kwargs={"tools": [{"google_search_retrieval": {}}]}
    )
    
    # Define Fallbacks in Order
    fallback_models = [
        "gemini-1.5-pro",        # 2
        "gemini-2.5-flash",      # 3
        "gemini-2.0-flash",      # 4
        "gemini-2.5-flash-lite", # 5
        "gemini-1.5-flash",      # 6
        "gemini-1.5-flash-8b"    # 7
    ]
    
    # Create Google Runnables
    runnables = [ChatGoogleGenerativeAI(model=m, **defaults) for m in fallback_models]
    
    # 8. DeepSeek (Ultimate Fallback)
    if DEEPSEEK_API_KEY:
        deepseek = ChatOpenAI(
            base_url="https://api.deepseek.com", 
            model="deepseek-chat", 
            api_key=DEEPSEEK_API_KEY,
            temperature=0.3
        )
        runnables.append(deepseek)
        
    return primary.with_fallbacks(runnables)

# Global Cache for Details (Simple Dict: user_id -> detail_text)
# In production, use a TTL cache or database.
LAST_ANALYSIS_CACHE = {}

async def analyze_text_gemini(text, status_msg=None, lang_code="fa"):
    """Analyze text using Smart Chain Fallback with Live Status Updates"""
    if not SETTINGS["fact_check"]: return None

    # Map lang_code to English name for Prompt
    lang_map = {"fa": "Persian (Farsi)", "en": "English", "fr": "French"}
    target_lang = lang_map.get(lang_code, "Persian")

    try:
        logger.info(f"üß† STARTING AI ANALYSIS ({target_lang}) for text: {text[:20]}...")
        prompt_text = (
            "You are a professional Fact-Check Assistant. "
            f"Analyze the following text. Answer strictly in **{target_lang}** language.\n\n"
            "IMPORTANT: Telegram DOES NOT support Tables. Do NOT use Markdown Tables (no | pipes).\n"
            "Use this LIST format instead:\n\n"
            "PART 1: SUMMARY\n"
            "- Status: (‚úÖ Verified / ‚ö†Ô∏è Misleading / ‚ùå False)\n\n"
            "1Ô∏è‚É£ **Claim:** [Quote the claim]\n"
            "   ‚úÖ **Status:** [True/False]\n"
            "   üìö **Source:** [Title + Link]\n\n"
            "2Ô∏è‚É£ **Claim:** ...\n\n"
            "- **Conclusion:** [Brief summary]\n\n"
            "|||SPLIT|||\n\n"
            "PART 2: DEEP DIVE\n"
            "- Detail Scientific Analysis.\n"
            "- Biological Mechanisms.\n"
            "- **Academic References:** [Full Title + Link]\n"
            f"Text:\n{text}"
        )
        
        chain = get_smart_chain()
        logger.info("üöÄ Invoking LangChain...")
        
        # Callbacks for Live Updates
        config = {}
        if status_msg:
             config["callbacks"] = [StatusUpdateCallback(status_msg, get_msg)]

        # Invoke Chain (Async)
        response = await chain.ainvoke(
            [HumanMessage(content=prompt_text)],
            config=config
        )
        
        # Log metadata to see which model was used
        model_used = response.response_metadata.get('model_name', 'Unknown')
        logger.info(f"‚úÖ Response from {model_used}. Split Token Present: {'|||SPLIT|||' in response.content}")
        return response

    except Exception as e:
        logger.error(f"‚ùå SmartChain Error: {e}", exc_info=True)
        return None

# 4. Localization Dictionary
# 4. Localization Dictionary
MESSAGES = {
    "fa": {
        "welcome": "üëã **ÿ≥ŸÑÿßŸÖ {name}!**\nÿ®Ÿá ÿ±ÿ®ÿßÿ™ ŸáŸàÿ¥ŸÖŸÜÿØ ÿÆŸàÿ¥ ÿ¢ŸÖÿØ€åÿØ.\n\nüîª ÿßÿ≤ ŸÖŸÜŸà€å Ÿæÿß€å€åŸÜ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ €åÿß ŸÑ€åŸÜ⁄© ÿ®ŸÅÿ±ÿ≥ÿ™€åÿØ:",
        "btn_status": "üìä Ÿàÿ∂ÿπ€åÿ™ ÿ±ÿ®ÿßÿ™",
        "btn_help": "üÜò ÿ±ÿßŸáŸÜŸÖÿß",
        "btn_dl": "üì• ŸÖÿØ€åÿ±€åÿ™ ÿØÿßŸÜŸÑŸàÿØ",
        "btn_fc": "üß† ŸÖÿØ€åÿ±€åÿ™ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å",
        "btn_stop": "üõë ÿÆÿßŸÖŸàÿ¥ ⁄©ÿ±ÿØŸÜ ÿ±ÿ®ÿßÿ™",
        "btn_lang_fa": "üáÆüá∑ ŸÅÿßÿ±ÿ≥€å",
        "btn_lang_en": "üá∫üá∏ English",
        "btn_lang_fr": "üá´üá∑ Fran√ßais",
        "status_fmt": (
            "üìä **Ÿàÿ∂ÿπ€åÿ™ ŸÑÿ≠ÿ∏Ÿá‚Äåÿß€å ÿ±ÿ®ÿßÿ™ ŸáŸàÿ¥ŸÖŸÜÿØ**\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üì• **ÿ≥€åÿ≥ÿ™ŸÖ ÿØÿßŸÜŸÑŸàÿØ:**        {dl}\n"
            "üß† **ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å:**      {fc}\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üîª ÿ®ÿ±ÿß€å ÿ™ÿ∫€å€åÿ± ÿßÿ≤ ÿØ⁄©ŸÖŸá‚ÄåŸáÿß€å ÿ≤€åÿ± ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ."
        ),
        "help_msg": (
            "üìö **ÿ±ÿßŸáŸÜŸÖÿß€å ⁄©ÿßŸÖŸÑ ÿ±ÿ®ÿßÿ™:**\n\n"
            "üì• **ÿØÿßŸÜŸÑŸàÿØÿ± ÿß€åŸÜÿ≥ÿ™ÿß⁄Øÿ±ÿßŸÖ:**\n"
            "‚Ä¢ ŸÑ€åŸÜ⁄© Ÿæÿ≥ÿ™ €åÿß ÿ±€åŸÑÿ≤ (Reels) ÿ±ÿß ÿ®ŸÅÿ±ÿ≥ÿ™€åÿØ -> Ÿà€åÿØ€åŸà ÿ®ÿß ÿ®ÿßŸÑÿßÿ™ÿ±€åŸÜ ⁄©€åŸÅ€åÿ™ ÿØÿßŸÜŸÑŸàÿØ ŸÖ€å‚Äåÿ¥ŸàÿØ.\n\n"
            "üß† **ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å (ŸÅ⁄©ÿ™‚Äå⁄Ü⁄©€åŸÜ⁄Ø):**\n"
            "‚Ä¢ Ÿáÿ± ŸÖÿ™ŸÜ€å (ÿßÿÆÿ®ÿßÿ±ÿå ÿ¥ÿß€åÿπŸáÿå ⁄©Ÿæÿ¥ŸÜ) ÿ®ŸÅÿ±ÿ≥ÿ™€åÿØ -> ÿ±ÿ®ÿßÿ™ ÿ®ÿß €∏ ŸÖÿØŸÑ ŸáŸàÿ¥ŸÖŸÜÿØ (⁄ØŸà⁄ØŸÑ + ÿØ€åŸæ‚Äåÿ≥€å⁄©) ÿ¢ŸÜ ÿ±ÿß ÿ®ÿ±ÿ±ÿ≥€å Ÿà ÿ™ÿß€å€åÿØ/ÿ±ÿØ ŸÖ€å‚Äå⁄©ŸÜÿØ.\n"
            "‚Ä¢ ŸÇÿßÿ®ŸÑ€åÿ™ ÿ¨ÿ≥ÿ™ÿ¨Ÿà ÿØÿ± ⁄ØŸà⁄ØŸÑ ÿ®ÿ±ÿß€å ÿ®ÿ±ÿ±ÿ≥€å ÿßÿÆÿ®ÿßÿ± ŸÑÿ≠ÿ∏Ÿá‚Äåÿß€å ŸÅÿπÿßŸÑ ÿßÿ≥ÿ™.\n\n"
            "‚öôÔ∏è **ÿØÿ≥ÿ™Ÿàÿ±ÿßÿ™:**\n"
            "/start - ÿ¥ÿ±Ÿàÿπ ŸÖÿ¨ÿØÿØ\n"
            "/status - Ÿàÿ∂ÿπ€åÿ™ ÿ±ÿ®ÿßÿ™\n"
            "/check [ŸÖÿ™ŸÜ] - ÿ™ÿ≠ŸÑ€åŸÑ ŸÖÿ™ŸÜ ÿØÿ± ⁄Øÿ±ŸàŸá‚ÄåŸáÿß\n"
            "/stop - ÿÆÿßŸÖŸàÿ¥ ⁄©ÿ±ÿØŸÜ ÿ±ÿ®ÿßÿ™ (ÿßÿØŸÖ€åŸÜ)\n"
        ),
        "dl_on": "‚úÖ ŸÅÿπÿßŸÑ",
        "dl_off": "‚ùå ÿ∫€åÿ±ŸÅÿπÿßŸÑ",
        "fc_on": "‚úÖ ŸÅÿπÿßŸÑ",
        "fc_off": "‚ùå ÿ∫€åÿ±ŸÅÿπÿßŸÑ",
        "action_dl": "üì• Ÿàÿ∂ÿπ€åÿ™ ÿØÿßŸÜŸÑŸàÿØ ÿ™ÿ∫€å€åÿ± ⁄©ÿ±ÿØ: {state}",
        "action_fc": "üß† Ÿàÿ∂ÿπ€åÿ™ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å ÿ™ÿ∫€å€åÿ± ⁄©ÿ±ÿØ: {state}",
        "lang_set": "üáÆüá∑ ÿ≤ÿ®ÿßŸÜ ÿ±Ÿà€å **ŸÅÿßÿ±ÿ≥€å** ÿ™ŸÜÿ∏€åŸÖ ÿ¥ÿØ.",
        "menu_closed": "‚ùå ŸÖŸÜŸà ÿ®ÿ≥ÿ™Ÿá ÿ¥ÿØ. ÿ®ÿ±ÿß€å ÿ®ÿßÿ≤ ⁄©ÿ±ÿØŸÜ ŸÖÿ¨ÿØÿØ /start ÿ®ÿ≤ŸÜ€åÿØ.",
        "only_admin": "‚õî ŸÅŸÇÿ∑ ÿßÿØŸÖ€åŸÜ ŸÖ€å‚Äåÿ™ŸàÿßŸÜÿØ ÿß€åŸÜ ⁄©ÿßÿ± ÿ±ÿß ÿßŸÜÿ¨ÿßŸÖ ÿØŸáÿØ.",
        "bot_stop": "üõë ÿ±ÿ®ÿßÿ™ ÿØÿ± ÿ≠ÿßŸÑ ÿÆÿßŸÖŸàÿ¥ ÿ¥ÿØŸÜ...",
        "analyzing": "üß† ÿØÿ± ÿ≠ÿßŸÑ ÿ™ÿ≠ŸÑ€åŸÑ ÿØŸÇ€åŸÇ ÿπŸÑŸÖ€å... (ŸÖÿØŸÑ‚ÄåŸáÿß€å Gemini + DeepSeek w/ Search)",
        "too_short": "‚ö†Ô∏è ŸÖÿ™ŸÜ ÿ®ÿ±ÿß€å ÿ™ÿ≠ŸÑ€åŸÑ ÿÆ€åŸÑ€å ⁄©Ÿàÿ™ÿßŸá ÿßÿ≥ÿ™.",
        "downloading": "üì• ÿØÿ± ÿ≠ÿßŸÑ ÿØÿßŸÜŸÑŸàÿØ Ÿà€åÿØ€åŸà... ŸÑÿ∑ŸÅÿß ÿµÿ®ÿ± ⁄©ŸÜ€åÿØ.",
        "uploading": "üì§ ÿØÿ± ÿ≠ÿßŸÑ ÿ¢ŸæŸÑŸàÿØ ÿ®Ÿá ÿ™ŸÑ⁄Øÿ±ÿßŸÖ...",
        "err_dl": "‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿØÿßŸÜŸÑŸàÿØ. ŸÑ€åŸÜ⁄© ÿ®ÿ±ÿ±ÿ≥€å ÿ¥ŸàÿØ.",
        "err_api": "‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿßÿ±ÿ™ÿ®ÿßÿ∑ ÿ®ÿß ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å. ŸÑÿ∑ŸÅÿß ÿ®ÿπÿØÿß ÿ™ŸÑÿßÿ¥ ⁄©ŸÜ€åÿØ."
    },
    "en": {
        "welcome": "üëã **Hello {name}!**\nWelcome to Smart Bot.\n\nüîª Use the menu below or send a link:",
        "btn_status": "üìä Status",
        "btn_help": "üÜò Help",
        "btn_dl": "üì• Toggle Download",
        "btn_fc": "üß† Toggle AI",
        "btn_stop": "üõë Stop Bot",
        "btn_lang_fa": "üáÆüá∑ ŸÅÿßÿ±ÿ≥€å",
        "btn_lang_en": "üá∫üá∏ English",
        "btn_lang_fr": "üá´üá∑ Fran√ßais",
        "status_fmt": (
            "üìä **Live System Status**\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üì• **Downloader:**        {dl}\n"
            "üß† **AI Fact-Check:**     {fc}\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üîª Use buttons below to toggle."
        ),
        "help_msg": (
            "üìö **Full Bot Guide:**\n\n"
            "üì• **Instagram Downloader:**\n"
            "‚Ä¢ Send Post/Reels Link -> Download High Quality Video.\n\n"
            "üß† **AI Fact-Checker:**\n"
            "‚Ä¢ Send any text -> Analyzed by 8 AI Models (Google + DeepSeek).\n"
            "‚Ä¢ Real-time Google Search enabled for latest news.\n\n"
            "‚öôÔ∏è **Commands:**\n"
            "/start - Restart Menu\n"
            "/status - Check Settings\n"
            "/check [text] - Check text in groups\n"
            "/stop - Shutdown Bot (Admin)\n"
        ),
        "dl_on": "‚úÖ On ",
        "dl_off": "‚ùå Off",
        "fc_on": "‚úÖ On ",
        "fc_off": "‚ùå Off",
        "action_dl": "üì• Download status: {state}",
        "action_fc": "üß† AI status: {state}",
        "lang_set": "üá∫üá∏ Language set to **English**.",
        "menu_closed": "‚ùå Menu closed. Type /start to open.",
        "only_admin": "‚õî Admin only.",
        "bot_stop": "üõë Bot is shutting down...",
        "analyzing": "üß† Analyzing text... (Smart Chain)",
        "too_short": "‚ö†Ô∏è Text is too short.",
        "downloading": "üì• Downloading video...",
        "uploading": "üì§ Uploading to Telegram...",
        "err_dl": "‚ùå Download failed.",
        "err_api": "‚ö†Ô∏è AI API Error."
    },
    "fr": {
        "welcome": "üëã **Bonjour {name}!**\nBienvenue.\n\nüîª Utilisez le menu ci-dessous :",
        "btn_status": "üìä √âtat",
        "btn_help": "üÜò Aide",
        "btn_dl": "üì• T√©l√©chargement",
        "btn_fc": "üß† IA",
        "btn_stop": "üõë Arr√™ter",
        "btn_lang_fa": "üáÆüá∑ ŸÅÿßÿ±ÿ≥€å",
        "btn_lang_en": "üá∫üá∏ English",
        "btn_lang_fr": "üá´üá∑ Fran√ßais",
        "status_fmt": (
            "üìä **√âtat du Syst√®me**\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üì• **T√©l√©chargement:**    {dl}\n"
            "üß† **IA Fact-Check:**     {fc}\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "üîª Utilisez les boutons pour changer."
        ),
        "help_msg": (
            "üìö **Guide Complet:**\n\n"
            "üì• **Instagram:**\n"
            "‚Ä¢ Envoyez lien (Reels/Post) -> T√©l√©chargement HD.\n\n"
            "üß† **Intelligence Artificielle:**\n"
            "‚Ä¢ Envoyez un texte -> Analyse par 8 mod√®les IA.\n\n"
            "‚öôÔ∏è **Commandes:**\n"
            "/start - Menu\n"
            "/status - √âtat\n"
            "/check [texte] - V√©rifier le texte\n"
        ),
        "dl_on": "‚úÖ Activ√©",
        "dl_off": "‚ùå D√©sactiv√©",
        "fc_on": "‚úÖ Activ√©",
        "fc_off": "‚ùå D√©sactiv√©",
        "action_dl": "üì• T√©l√©chargement: {state}",
        "action_fc": "üß† IA: {state}",
        "lang_set": "üá´üá∑ Langue d√©finie sur **Fran√ßais**.",
        "menu_closed": "‚ùå Menu ferm√©. Tapez /start.",
        "only_admin": "‚õî Admin seulement.",
        "bot_stop": "üõë Arr√™t du bot...",
        "analyzing": "üß† Analyse en cours...",
        "too_short": "‚ö†Ô∏è Texte trop court.",
        "downloading": "üì• T√©l√©chargement...",
        "uploading": "üì§ Envoi...",
        "err_dl": "‚ùå √âchec du t√©l√©chargement.",
        "err_api": "‚ö†Ô∏è Erreur API."
    }
}

def get_msg(key, user_id=None):
    """Retrieve localized message based on User ID or Global Settings"""
    lang = "fa"
    if user_id and user_id in USER_LANG:
        lang = USER_LANG[user_id]
        # logger.info(f"DEBUG: Found User {user_id} Lang: {lang}") # Debug
    else:
        lang = SETTINGS.get("lang", "fa")
    
    # Validation
    if lang not in MESSAGES: lang = "fa"
    
    return MESSAGES.get(lang, MESSAGES["en"]).get(key, MESSAGES["en"].get(key, ""))

# ==============================================================================
# LOGIC: MENU & KEYBOARDS
# ==============================================================================

def get_main_keyboard(user_id):
    """Generate the dynamic keyboard based on User Language"""
    kb = [
        [KeyboardButton(get_msg("btn_status", user_id)), KeyboardButton(get_msg("btn_help", user_id))],
        [KeyboardButton(get_msg("btn_dl", user_id)), KeyboardButton(get_msg("btn_fc", user_id))],
        [KeyboardButton("üáÆüá∑ ŸÅÿßÿ±ÿ≥€å"), KeyboardButton("üá∫üá∏ English"), KeyboardButton("üá´üá∑ Fran√ßais")]
    ]
    if user_id == SETTINGS["admin_id"]:
        # Append to the first row (Status, Help, Stop) to keep it 3 rows total
        kb[0].append(KeyboardButton(get_msg("btn_stop", user_id)))
    return ReplyKeyboardMarkup(kb, resize_keyboard=True)

async def send_welcome(update: Update):
    """Send welcome message with menu"""
    user = update.effective_user
    text = get_msg("welcome", user.id).format(name=user.first_name)
    await update.message.reply_text(
        text, 
        parse_mode='Markdown',
        reply_markup=get_main_keyboard(user.id)
    )





# ==============================================================================
# HELPERS
# ==============================================================================

async def smart_reply(msg, status_msg, response, user_id):
    """Handles AI response sending with Chunking, Caching, and Markdown Safety"""
    if not response:
        await status_msg.edit_text(get_msg("err_api"))
        return

    # 1. Determine Header
    model_name = "Gemini"
    if "model_name" in response.response_metadata:
        model_name = response.response_metadata["model_name"]
    elif "token_usage" in response.response_metadata: # DeepSeek usually relies on this
        model_name = "DeepSeek"
    
    header = f"üß† **Analysis by {model_name}:**"
    
    # 2. Parse Split (Summary vs Detail)
    full_content = response.content
    
    # Try different split markers just in case
    split_marker = "|||SPLIT|||"
    if split_marker not in full_content:
        # Fallback: Try to find a natural break if AI ignored instructions
        if "---" in full_content:
            split_marker = "---"
    
    if split_marker in full_content and split_marker != "---":
        parts = full_content.split(split_marker)
        summary_text = parts[0].strip()
        detail_text = parts[1].strip()
        # CACHE DETAIL
        LAST_ANALYSIS_CACHE[user_id] = f"{header} (Deep Dive)\n\n{detail_text}"
        logger.info(f"üíæ Detail Cached for User {user_id}")
    else:
        # Fallback if AI completely failed to split: Send everything but warn
        logger.warning(f"‚ö†Ô∏è Split Token NOT found in response (Len: {len(full_content)})")
        summary_text = full_content
        LAST_ANALYSIS_CACHE[user_id] = "‚ö†Ô∏è ÿ¨ÿ≤ÿ¶€åÿßÿ™ ÿ®€åÿ¥ÿ™ÿ±€å ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜ€åÿ≥ÿ™ (ŸÖÿØŸÑ Ÿæÿßÿ≥ÿÆ €å⁄©Ÿæÿßÿ±⁄ÜŸá ÿØÿßÿØ)."

    final_text = f"{header}\n\n{summary_text}"
    
    # 3. Send Summary
    # Telegram Limit is 4096.
    if len(final_text) > 4000:
         # If Summary itself is huge, we must chunk it
         chunks = [final_text[i:i+4000] for i in range(0, len(final_text), 4000)]
         for i, chunk in enumerate(chunks):
             try:
                 if i == 0:
                     await status_msg.edit_text(chunk, parse_mode='Markdown')
                 else:
                     await msg.reply_text(chunk, parse_mode='Markdown')
             except Exception:
                 if i == 0: await status_msg.edit_text(chunk, parse_mode=None)
                 else: await msg.reply_text(chunk, parse_mode=None)
    else:
        # Normal Case
        try:
             await status_msg.edit_text(final_text, parse_mode='Markdown')
        except Exception:
             await status_msg.edit_text(final_text, parse_mode=None)

# ==============================================================================
# LOGIC: INSTAGRAM DOWNLOAD
# ==============================================================================

async def download_instagram(url, chat_id, bot):
    """Download and send video using yt-dlp"""
    try:
        # 1. Filename setup
        timestamp = int(asyncio.get_event_loop().time())
        filename = Path(f"insta_{timestamp}.mp4")
        
        # 2. Command
        cmd = [
            "yt-dlp",
            "-f", "best[ext=mp4]",
            "-o", str(filename),
            url
        ]
        
        # 3. Cookies if available
        cookie_file = Path("cookies.txt")
        if cookie_file.exists():
            cmd.insert(1, str(cookie_file))
            cmd.insert(1, "--cookies")

        # 4. Run Download
        process = await asyncio.create_subprocess_exec(
            *cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE
        )
        stdout, stderr = await process.communicate()
        
        if process.returncode != 0:
            logger.error(f"Download Error: {stderr.decode()}")
            return False

        # 5. Send to User
        if filename.exists():
            with open(filename, "rb") as video_file:
                await bot.send_video(
                    chat_id=chat_id,
                    video=video_file,
                    caption="ü§ñ Downloaded by SmartBot",
                    supports_streaming=True
                )
            # Cleanup
            filename.unlink()
            return True
        return False
        
    except Exception as e:
        logger.error(f"DL Exception: {e}")
        return False

# ==============================================================================
# HANDLERS
# ==============================================================================

# ==============================================================================
# PROCESSED HANDLERS (DEBUGGING ADDED)
# ==============================================================================

async def cmd_start_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info(f"üöÄ Command /start triggered by {update.effective_user.id}")
    await send_welcome(update)

async def cmd_close_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info("‚ùå Command /close triggered")
    await update.message.reply_text(
        get_msg("menu_closed"), 
        reply_markup=ReplyKeyboardRemove()
    )

async def cmd_status_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info("üìä Command /status triggered")
    dl_s = get_msg("dl_on") if SETTINGS["download"] else get_msg("dl_off")
    fc_s = get_msg("fc_on") if SETTINGS["fact_check"] else get_msg("fc_off")
    info = get_msg("status_fmt").format(dl=dl_s, fc=fc_s)
    await update.message.reply_text(info, parse_mode='Markdown')

async def cmd_toggle_dl_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info("üì• Command /toggle_dl triggered")
    SETTINGS["download"] = not SETTINGS["download"]
    state = get_msg("dl_on") if SETTINGS["download"] else get_msg("dl_off")
    await update.message.reply_text(get_msg("action_dl").format(state=state))

async def cmd_toggle_fc_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info("üß† Command /toggle_fc triggered")
    SETTINGS["fact_check"] = not SETTINGS["fact_check"]
    state = get_msg("fc_on") if SETTINGS["fact_check"] else get_msg("fc_off")
    await update.message.reply_text(get_msg("action_fc").format(state=state))

async def cmd_check_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info("‚úÖ Command /check triggered")
    msg = update.message
    # Check if reply or arguments
    target_text = ""
    if msg.reply_to_message and msg.reply_to_message.text:
        target_text = msg.reply_to_message.text
    elif context.args:
        target_text = " ".join(context.args)
    
    if not target_text:
        await msg.reply_text("‚õî Reply to a message or provide text: `/check <text>`")
        return

    status_msg = await msg.reply_text(get_msg("analyzing"))
    # --- 3. AI ANALYSIS (Fallback) ---
    
    if SETTINGS["fact_check"] and len(text) >= SETTINGS["min_fc_len"]:
        status_msg = await msg.reply_text(get_msg("analyzing"))
        response = await analyze_text_gemini(text)
        
        if response:
            header = "üß† **Gemini Analysis:**"
            # DeepSeek detection
            if "model_name" in response.response_metadata or "token_usage" in response.response_metadata:
                header = "üß† **DeepSeek Analysis:**"
            
            final_text = f"{header}\n\n{response.content}"
            
            try:
                # Try Markdown first (Prettiest)
                await status_msg.edit_text(final_text, parse_mode='Markdown')
            except Exception as e:
                logger.warning(f"Markdown Fail ({e}), sending plain text.")
                # Fallback to Plain Text (Reliable)
                await status_msg.edit_text(final_text, parse_mode=None)
        else:
            await status_msg.delete() 
        return

async def cmd_check_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info("‚úÖ Command /check triggered")
    msg = update.message
    user_id = update.effective_user.id
    lang = USER_LANG.get(user_id, "fa")

    # Check if reply or arguments
    target_text = ""
    if msg.reply_to_message and msg.reply_to_message.text:
        target_text = msg.reply_to_message.text
    elif context.args:
        target_text = " ".join(context.args)
    
    if not target_text:
        await msg.reply_text("‚õî Reply to a message or provide text: `/check <text>`")
        return

    status_msg = await msg.reply_text(get_msg("analyzing"))
    response = await analyze_text_gemini(target_text, lang)
    
    await smart_reply(msg, status_msg, response, user_id)

async def cmd_stop_bot_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    if user_id != SETTINGS["admin_id"]:
        await update.message.reply_text(get_msg("only_admin"))
        return
    await update.message.reply_text(get_msg("bot_stop"), reply_markup=ReplyKeyboardRemove())
    logger.info("üõë KILLING PROCESS WITH SIGKILL (9)")
    os.kill(os.getpid(), signal.SIGKILL)

async def global_message_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """MASTER HANDLER: Processes ALL text messages"""
    msg = update.message
    if not msg or not msg.text: return
    text = msg.text.strip()
    user = update.effective_user
    user_id = user.id
    
    # Ensure User Lang
    if user_id not in USER_LANG:
        USER_LANG[user_id] = "fa"
    lang = USER_LANG[user_id]

    logger.info(f"üì® Message received: '{text}' from {user.id} ({lang})")

    # --- 1. MENU COMMANDS (Check by Emoji/Start) --- 
    
    # Status
    if text.startswith("üìä"):
        dl_s = get_msg("dl_on", user_id) if SETTINGS["download"] else get_msg("dl_off", user_id)
        fc_s = get_msg("fc_on", user_id) if SETTINGS["fact_check"] else get_msg("fc_off", user_id)
        info = get_msg("status_fmt", user_id).format(dl=dl_s, fc=fc_s)
        await msg.reply_text(info, parse_mode='Markdown')
        return

    # Language Switching
    if "ŸÅÿßÿ±ÿ≥€å" in text:
        USER_LANG[user_id] = "fa"
        await msg.reply_text("‚úÖ ÿ≤ÿ®ÿßŸÜ ŸÅÿßÿ±ÿ≥€å ÿßŸÜÿ™ÿÆÿßÿ® ÿ¥ÿØ.", reply_markup=get_main_keyboard(user_id))
        return
    if "English" in text:
        USER_LANG[user_id] = "en"
        await msg.reply_text("‚úÖ English language selected.", reply_markup=get_main_keyboard(user_id))
        logger.info(f"üá∫üá∏ User {user_id} switched to English")
        return
    if "Fran√ßais" in text:
        USER_LANG[user_id] = "fr"
        await msg.reply_text("‚úÖ Langue fran√ßaise s√©lectionn√©e.", reply_markup=get_main_keyboard(user_id))
        return
        
    # Help
    if text.startswith("‚ÑπÔ∏è") or text.startswith("üÜò"):
        help_text = get_msg("help_msg", user_id)
        await msg.reply_text(help_text, parse_mode='Markdown') 
        return

    # Toggle DL
    if text.startswith("üì•"):
        SETTINGS["download"] = not SETTINGS["download"]
        state = get_msg("dl_on", user_id) if SETTINGS["download"] else get_msg("dl_off", user_id)
        await msg.reply_text(get_msg("action_dl", user_id).format(state=state))
        return

    # Toggle FC
    if text.startswith("üß†"):
        SETTINGS["fact_check"] = not SETTINGS["fact_check"]
        state = get_msg("fc_on", user_id) if SETTINGS["fact_check"] else get_msg("fc_off", user_id)
        await msg.reply_text(get_msg("action_fc", user_id).format(state=state))
        return

    # Stop (Button)
    if text.startswith("üõë") and user_id == SETTINGS["admin_id"]:
        logger.info("üõë Stop Button Triggered")
        await msg.reply_text(get_msg("bot_stop", user_id), reply_markup=ReplyKeyboardRemove())
        await asyncio.sleep(1)
        os.kill(os.getpid(), signal.SIGKILL)
        return

    # --- 2. INSTAGRAM LINK CHECK ---
    if "instagram.com" in text:
        if not SETTINGS["download"]:
            await msg.reply_text("‚ö†Ô∏è " + get_msg("dl_off", user_id))
            return
            
        status_msg = await msg.reply_text(get_msg("downloading", user_id))
        
        success = await download_instagram(text, msg.chat_id, context.bot)
        if success:
            await status_msg.delete()
        else:
            await status_msg.edit_text(get_msg("err_dl", user_id))
        return

    # --- 3. AI ANALYSIS (Fallback) ---
    
    if SETTINGS["fact_check"] and len(text) >= SETTINGS["min_fc_len"]:
        status_msg = await msg.reply_text(get_msg("analyzing", user_id))
        response = await analyze_text_gemini(text, status_msg, lang)
        
        await smart_reply(msg, status_msg, response, user_id)
        return

# ==============================================================================
# MAIN EXECUTION
# ==============================================================================

async def cmd_detail_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Fetches the cached detailed analysis (Zero-Cost)"""
    logger.info("üîç Command /detail triggered")
    msg = update.message
    user_id = update.effective_user.id
    
    # Check Cache
    detail_text = LAST_ANALYSIS_CACHE.get(user_id)
    
    if not detail_text:
        await msg.reply_text("‚õî Ÿá€å⁄Ü ÿ™ÿ≠ŸÑ€åŸÑ ÿ∞ÿÆ€åÿ±Ÿá‚Äåÿ¥ÿØŸá‚Äåÿß€å ŸÖŸàÿ¨ŸàÿØ ŸÜ€åÿ≥ÿ™. ÿßÿ®ÿ™ÿØÿß €å⁄© ŸÖÿ™ŸÜ ÿ±ÿß ÿ™ÿ≠ŸÑ€åŸÑ ⁄©ŸÜ€åÿØ.")
        return

    await msg.reply_text(f"üî¨ **Deep Dive Analysis:**\n\n{detail_text}", parse_mode='Markdown')

def main():
    if not TELEGRAM_TOKEN:
        print("‚ùå Error: TELEGRAM_BOT_TOKEN not found in .env")
        return

    print("üöÄ Starting SmartBot Core...")
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()

    # Commands
    app.add_handler(CommandHandler("start", cmd_start_handler))
    app.add_handler(CommandHandler("help", cmd_start_handler)) # Reuse start for help
    app.add_handler(CommandHandler("close", cmd_close_handler))
    app.add_handler(CommandHandler("status", cmd_status_handler))
    app.add_handler(CommandHandler("toggle_dl", cmd_toggle_dl_handler))
    app.add_handler(CommandHandler("toggle_fc", cmd_toggle_fc_handler))
    app.add_handler(CommandHandler("check", cmd_check_handler))
    app.add_handler(CommandHandler("detail", cmd_detail_handler)) # NEW COMMAND
    app.add_handler(CommandHandler("stop", cmd_stop_bot_handler))

    # All Messages (Text)
    app.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), global_message_handler))

    print("‚úÖ Bot is Polling...")
    app.run_polling()

if __name__ == "__main__":
    main()
